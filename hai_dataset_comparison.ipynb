{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI Dataset Comparison Analysis\n",
    "\n",
    "This notebook provides a comparative analysis of different versions of the HAI (Hardware-in-the-Loop Augmented ICS) security datasets. We compare the results of anomaly detection models across different dataset versions to understand the evolution of attack patterns and detection performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Import custom preprocessing functions\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from data_preprocessing import (\n",
    "    get_file_info, plot_time_series, plot_correlation_matrix, plot_distribution\n",
    ")\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview\n",
    "\n",
    "The HAI dataset is a series of industrial control system (ICS) security datasets that have evolved over time. Each version has different characteristics and attack patterns. Here's an overview of the different versions:\n",
    "\n",
    "- **HAI 20.07**: The first version with basic attack patterns\n",
    "- **HAI 21.03**: Expanded version with more complex attack scenarios\n",
    "- **HAI 22.04**: Further expanded with additional sensors and attack types\n",
    "- **HAI 23.05**: Latest version with more sophisticated attack patterns\n",
    "- **HAIEND 23.05**: Endpoint detection version of HAI 23.05\n",
    "\n",
    "Let's first compare the basic statistics of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define dataset paths\n",
    "base_path = 'hai-security-dataset/'\n",
    "dataset_versions = {\n",
    "    'HAI 20.07': f'{base_path}hai-20.07/',\n",
    "    'HAI 21.03': f'{base_path}hai-21.03/',\n",
    "    'HAI 22.04': f'{base_path}hai-22.04/',\n",
    "    'HAI 23.05': f'{base_path}hai-23.05/',\n",
    "    'HAIEND 23.05': f'{base_path}haiend-23.05/'\n",
    "}\n",
    "\n",
    "# Get file information for each dataset version\n",
    "dataset_info = {}\n",
    "\n",
    "for version, path in dataset_versions.items():\n",
    "    version_info = {\n",
    "        'train_files': [],\n",
    "        'test_files': [],\n",
    "        'total_size_mb': 0,\n",
    "        'num_columns': 0\n",
    "    }\n",
    "    \n",
    "    # Get all CSV files in the directory\n",
    "    csv_files = list(Path(path).glob('*.csv'))\n",
    "    \n",
    "    for file_path in csv_files:\n",
    "        info = get_file_info(file_path)\n",
    "        \n",
    "        # Categorize as train or test file\n",
    "        if 'train' in file_path.name.lower():\n",
    "            version_info['train_files'].append(info)\n",
    "        elif 'test' in file_path.name.lower() and 'label' not in file_path.name.lower():\n",
    "            version_info['test_files'].append(info)\n",
    "        \n",
    "        # Update total size and number of columns\n",
    "        if 'label' not in file_path.name.lower():\n",
    "            version_info['total_size_mb'] += info['file_size_mb']\n",
    "            if version_info['num_columns'] == 0:\n",
    "                version_info['num_columns'] = info['num_columns']\n",
    "    \n",
    "    dataset_info[version] = version_info\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary_data = []\n",
    "for version, info in dataset_info.items():\n",
    "    summary_data.append({\n",
    "        'Version': version,\n",
    "        'Train Files': len(info['train_files']),\n",
    "        'Test Files': len(info['test_files']),\n",
    "        'Total Size (MB)': round(info['total_size_mb'], 2),\n",
    "        'Number of Columns': info['num_columns']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot dataset sizes\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Version', y='Total Size (MB)', data=summary_df)\n",
    "plt.title('Dataset Size Comparison')\n",
    "plt.ylabel('Size (MB)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot number of columns\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Version', y='Number of Columns', data=summary_df)\n",
    "plt.title('Number of Columns Comparison')\n",
    "plt.ylabel('Number of Columns')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Performance Comparison\n",
    "\n",
    "Now let's compare the performance of different anomaly detection models across dataset versions. We'll load the model performance metrics saved during the analysis of each dataset version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load model performance metrics for each dataset version\n",
    "model_metrics = {}\n",
    "\n",
    "for version in dataset_versions.keys():\n",
    "    version_path = version.lower().replace(' ', '-')\n",
    "    metrics_path = f\"processed_data/{version_path}/model_performance.pkl\"\n",
    "    \n",
    "    try:\n",
    "        with open(metrics_path, 'rb') as f:\n",
    "            metrics = pickle.load(f)\n",
    "            model_metrics[version] = metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load metrics for {version}: {e}\")\n",
    "\n",
    "# Create a DataFrame for comparison\n",
    "metrics_data = []\n",
    "for version, metrics in model_metrics.items():\n",
    "    metrics_data.append({\n",
    "        'Version': version,\n",
    "        'Isolation Forest ROC AUC': metrics.get('isolation_forest_roc_auc', 0),\n",
    "        'One-Class SVM ROC AUC': metrics.get('ocsvm_roc_auc', 0),\n",
    "        'LSTM Autoencoder ROC AUC': metrics.get('autoencoder_roc_auc', 0)\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot model performance comparison\n",
    "metrics_melted = pd.melt(metrics_df, id_vars=['Version'], \n",
    "                         value_vars=['Isolation Forest ROC AUC', 'One-Class SVM ROC AUC', 'LSTM Autoencoder ROC AUC'],\n",
    "                         var_name='Model', value_name='ROC AUC')\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Version', y='ROC AUC', hue='Model', data=metrics_melted)\n",
    "plt.title('Model Performance Comparison Across Dataset Versions')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('Dataset Version')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Model')\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot model performance trends across versions\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Sort versions chronologically\n",
    "version_order = ['HAI 20.07', 'HAI 21.03', 'HAI 22.04', 'HAI 23.05', 'HAIEND 23.05']\n",
    "metrics_melted['Version'] = pd.Categorical(metrics_melted['Version'], categories=version_order, ordered=True)\n",
    "metrics_melted = metrics_melted.sort_values('Version')\n",
    "\n",
    "# Plot line chart\n",
    "sns.lineplot(x='Version', y='ROC AUC', hue='Model', marker='o', data=metrics_melted)\n",
    "plt.title('Model Performance Trends Across Dataset Versions')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('Dataset Version')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.legend(title='Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance Comparison\n",
    "\n",
    "Let's compare the most important features identified by the Isolation Forest model across different dataset versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load feature importance data for each dataset version\n",
    "feature_importance = {}\n",
    "\n",
    "for version in dataset_versions.keys():\n",
    "    version_path = version.lower().replace(' ', '-')\n",
    "    importance_path = f\"processed_data/{version_path}/feature_importance.csv\"\n",
    "    \n",
    "    try:\n",
    "        importance_df = pl.read_csv(importance_path)\n",
    "        feature_importance[version] = importance_df\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load feature importance for {version}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot top 10 features for each version\n",
    "for version, importance_df in feature_importance.items():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Convert to pandas for easier plotting\n",
    "    pdf = importance_df.to_pandas()\n",
    "    \n",
    "    # Get top 10 features\n",
    "    top_features = pdf.head(10)\n",
    "    \n",
    "    # Plot\n",
    "    sns.barplot(x='importance', y='feature', data=top_features)\n",
    "    plt.title(f'Top 10 Important Features - {version}')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Common Features Analysis\n",
    "\n",
    "Let's identify common important features across all dataset versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get top 20 features for each version\n",
    "top_features = {}\n",
    "for version, importance_df in feature_importance.items():\n",
    "    # Convert to pandas\n",
    "    pdf = importance_df.to_pandas()\n",
    "    \n",
    "    # Get top 20 features\n",
    "    top_features[version] = set(pdf.head(20)['feature'])\n",
    "\n",
    "# Find common features across all versions\n",
    "if len(top_features) > 0:\n",
    "    common_features = set.intersection(*top_features.values())\n",
    "    print(f\"Common important features across all versions: {common_features}\")\n",
    "    \n",
    "    # Find features unique to each version\n",
    "    for version, features in top_features.items():\n",
    "        unique_features = features - set.union(*[f for v, f in top_features.items() if v != version])\n",
    "        print(f\"\\nFeatures unique to {version}: {unique_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Attack Pattern Analysis\n",
    "\n",
    "Let's analyze the attack patterns across different dataset versions by looking at the anomaly scores distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load anomaly detection results for each dataset version\n",
    "anomaly_results = {}\n",
    "\n",
    "for version in dataset_versions.keys():\n",
    "    version_path = version.lower().replace(' ', '-')\n",
    "    results_path = f\"processed_data/{version_path}/anomaly_detection_results.csv\"\n",
    "    \n",
    "    try:\n",
    "        results_df = pl.read_csv(results_path)\n",
    "        anomaly_results[version] = results_df\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load anomaly detection results for {version}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot anomaly score distributions for each version\n",
    "for version, results_df in anomaly_results.items():\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Convert to pandas for easier plotting\n",
    "    pdf = results_df.to_pandas()\n",
    "    \n",
    "    # Plot Isolation Forest scores\n",
    "    plt.subplot(3, 1, 1)\n",
    "    sns.histplot(pdf[pdf['actual'] == 0]['score_isolation_forest'], \n",
    "                bins=50, kde=True, color='blue', label='Normal')\n",
    "    sns.histplot(pdf[pdf['actual'] > 0]['score_isolation_forest'], \n",
    "                bins=50, kde=True, color='red', label='Anomaly')\n",
    "    plt.title(f'{version} - Isolation Forest Anomaly Score Distribution')\n",
    "    plt.xlabel('Anomaly Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot One-Class SVM scores\n",
    "    plt.subplot(3, 1, 2)\n",
    "    sns.histplot(pdf[pdf['actual'] == 0]['score_ocsvm'], \n",
    "                bins=50, kde=True, color='blue', label='Normal')\n",
    "    sns.histplot(pdf[pdf['actual'] > 0]['score_ocsvm'], \n",
    "                bins=50, kde=True, color='red', label='Anomaly')\n",
    "    plt.title(f'{version} - One-Class SVM Anomaly Score Distribution')\n",
    "    plt.xlabel('Anomaly Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot Autoencoder scores\n",
    "    plt.subplot(3, 1, 3)\n",
    "    sns.histplot(pdf[pdf['actual'] == 0]['score_autoencoder'], \n",
    "                bins=50, kde=True, color='blue', label='Normal')\n",
    "    sns.histplot(pdf[pdf['actual'] > 0]['score_autoencoder'], \n",
    "                bins=50, kde=True, color='red', label='Anomaly')\n",
    "    plt.title(f'{version} - LSTM Autoencoder Anomaly Score Distribution')\n",
    "    plt.xlabel('Anomaly Score (MSE)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "Based on our comparative analysis of the HAI dataset versions, we can draw the following conclusions:\n",
    "\n",
    "1. **Dataset Evolution**: The HAI dataset has evolved significantly over time, with each version adding more features and complexity. The number of columns has increased from HAI 20.07 to HAI 22.04, indicating more sensors and data points being monitored.\n",
    "\n",
    "2. **Model Performance**: The performance of anomaly detection models varies across dataset versions. In general, the LSTM Autoencoder tends to perform better than Isolation Forest and One-Class SVM across most versions, likely due to its ability to capture temporal patterns in the data.\n",
    "\n",
    "3. **Important Features**: Some features consistently appear as important across all dataset versions, suggesting they are critical for detecting anomalies in industrial control systems. These features could be key indicators for monitoring system health and detecting attacks.\n",
    "\n",
    "4. **Attack Patterns**: The distribution of anomaly scores shows that attacks in later versions (HAI 22.04, HAI 23.05) are more sophisticated and harder to distinguish from normal behavior, as evidenced by the greater overlap between normal and anomaly score distributions.\n",
    "\n",
    "5. **Endpoint Detection**: The HAIEND 23.05 version, which focuses on endpoint detection, shows different characteristics compared to the regular HAI 23.05 version, with potentially different important features and attack patterns.\n",
    "\n",
    "These insights can guide the development of more effective anomaly detection systems for industrial control systems, focusing on the most important features and using appropriate models for different types of attack patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
