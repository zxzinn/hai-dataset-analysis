{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI-20.07 Dataset Analysis: Efficient GRU with Attention Model\n",
    "\n",
    "This notebook implements an efficient Gated Recurrent Unit (GRU) model with attention mechanism for attack detection in industrial control systems using the HAI-20.07 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import psutil\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# TensorFlow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Conv1D, Flatten, Input, Dropout, BatchNormalization, MaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import class_weight\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Check for GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed sequence data\n",
    "with open('preprocessed_data/sequence_data.pkl', 'rb') as f:\n",
    "    sequence_data = pickle.load(f)\n",
    "\n",
    "X_train_seq = sequence_data['X_train_seq']\n",
    "y_train_seq = sequence_data['y_train_seq']\n",
    "X_test_seq = sequence_data['X_test_seq']\n",
    "y_test_seq = sequence_data['y_test_seq']\n",
    "X_train_seq_balanced = sequence_data['X_train_seq_balanced']\n",
    "y_train_seq_balanced = sequence_data['y_train_seq_balanced']\n",
    "TIME_STEPS = sequence_data['TIME_STEPS']\n",
    "STRIDE = sequence_data['STRIDE']\n",
    "\n",
    "print(\"X_train_seq_balanced shape:\", X_train_seq_balanced.shape)\n",
    "print(\"y_train_seq_balanced shape:\", y_train_seq_balanced.shape)\n",
    "print(\"X_test_seq shape:\", X_test_seq.shape)\n",
    "print(\"y_test_seq shape:\", y_test_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to measure memory usage accurately\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage in MB\"\"\"\n",
    "    # Force garbage collection before measuring memory\n",
    "    gc.collect()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_info = process.memory_info()\n",
    "    return memory_info.rss / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "# Function to calculate TensorFlow model size in MB\n",
    "def get_tf_model_size(model):\n",
    "    model.save(\"temp_model\")\n",
    "    size_bytes = sum(os.path.getsize(os.path.join(\"temp_model\", f)) for f in os.listdir(\"temp_model\") if os.path.isfile(os.path.join(\"temp_model\", f)))\n",
    "    import shutil\n",
    "    shutil.rmtree(\"temp_model\")\n",
    "    return size_bytes / (1024 * 1024)  # Convert to MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Efficient GRU with Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an efficient GRU model with attention using TensorFlow\n",
    "def create_gru_attention_model(input_shape, gru_units=16):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # GRU layer (using GRU instead of LSTM for efficiency)\n",
    "    gru_out = GRU(gru_units, return_sequences=True)(inputs)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = Dense(1, activation='tanh')(gru_out)\n",
    "    attention = tf.keras.layers.Reshape((-1,))(attention)\n",
    "    attention = tf.keras.layers.Activation('softmax')(attention)\n",
    "    attention = tf.keras.layers.Reshape((-1, 1))(attention)\n",
    "    \n",
    "    # Apply attention weights\n",
    "    context = tf.keras.layers.Multiply()([gru_out, attention])\n",
    "    context = tf.keras.layers.Lambda(lambda x: tf.keras.backend.sum(x, axis=1))(context)\n",
    "    \n",
    "    # Output layers\n",
    "    x = Dense(8, activation='relu')(context)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GRU model\n",
    "def train_gru_model(X_train, y_train, X_test, y_test):\n",
    "    # Calculate class weights for imbalanced data\n",
    "    class_weights = {0: 1.0, 1: len(y_train) / (2 * np.sum(y_train))}\n",
    "    print(f\"Class weights: {class_weights}\")\n",
    "    \n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)\n",
    "    \n",
    "    # Measure memory usage before training\n",
    "    memory_before = get_memory_usage()\n",
    "    \n",
    "    # Create model\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = create_gru_attention_model(input_shape)\n",
    "    \n",
    "    # Print model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=15,\n",
    "        batch_size=64,\n",
    "        validation_split=0.1,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Measure memory usage after training\n",
    "    memory_after = get_memory_usage()\n",
    "    memory_used = memory_after - memory_before\n",
    "    print(f\"Memory used: {memory_used:.2f} MB\")\n",
    "    \n",
    "    # Calculate model size\n",
    "    model_size = get_tf_model_size(model)\n",
    "    print(f\"Model size: {model_size:.2f} MB\")\n",
    "    \n",
    "    # Evaluate model\n",
    "    inference_start = time.time()\n",
    "    y_pred_proba = model.predict(X_test).reshape(-1)\n",
    "    inference_time = (time.time() - inference_start) / len(X_test)\n",
    "    print(f\"Average inference time per sample: {inference_time*1000:.4f} ms\")\n",
    "    \n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC: {auc_score:.4f}\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix - GRU with Attention')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        'model_name': 'GRU with Attention',\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc_score,\n",
    "        'training_time': training_time,\n",
    "        'inference_time': inference_time,\n",
    "        'memory_used': memory_used,\n",
    "        'model_size': model_size,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'history': history.history\n",
    "    }\n",
    "    \n",
    "    # Create directory for results if it doesn't exist\n",
    "    if not os.path.exists('model_results'):\n",
    "        os.makedirs('model_results')\n",
    "    \n",
    "    # Save results\n",
    "    with open('model_results/gru_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    \n",
    "    # Save model\n",
    "    model.save('model_results/gru_model')\n",
    "    \n",
    "    return model, y_pred, y_pred_proba, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GRU model\n",
    "print(\"Training Efficient GRU with Attention model...\")\n",
    "gru_model, y_pred_gru, y_prob_gru, gru_results = train_gru_model(X_train_seq_balanced, y_train_seq_balanced, X_test_seq, y_test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model to extract attention weights\n",
    "def create_attention_extraction_model(trained_model):\n",
    "    # Get the input layer\n",
    "    inputs = trained_model.input\n",
    "    \n",
    "    # Get the GRU layer output\n",
    "    gru_out = trained_model.layers[1].output\n",
    "    \n",
    "    # Get the attention weights\n",
    "    attention = trained_model.layers[2].output\n",
    "    attention = trained_model.layers[3].output\n",
    "    attention = trained_model.layers[4].output\n",
    "    attention = trained_model.layers[5].output\n",
    "    \n",
    "    # Create a model that outputs attention weights\n",
    "    attention_model = Model(inputs=inputs, outputs=attention)\n",
    "    \n",
    "    return attention_model\n",
    "\n",
    "# Extract attention weights for a sample\n",
    "attention_model = create_attention_extraction_model(gru_model)\n",
    "\n",
    "# Get a few attack samples from the test set\n",
    "attack_indices = np.where(y_test_seq == 1)[0]\n",
    "normal_indices = np.where(y_test_seq == 0)[0]\n",
    "\n",
    "# Select a few samples\n",
    "num_samples = 3\n",
    "attack_samples = X_test_seq[attack_indices[:num_samples]]\n",
    "normal_samples = X_test_seq[normal_indices[:num_samples]]\n",
    "\n",
    "# Get attention weights\n",
    "attack_attention = attention_model.predict(attack_samples)\n",
    "normal_attention = attention_model.predict(normal_samples)\n",
    "\n",
    "# Plot attention weights\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(2, num_samples, i + 1)\n",
    "    plt.plot(attack_attention[i].reshape(-1))\n",
    "    plt.title(f'Attack Sample {i+1} Attention')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Attention Weight')\n",
    "    \n",
    "    plt.subplot(2, num_samples, num_samples + i + 1)\n",
    "    plt.plot(normal_attention[i].reshape(-1))\n",
    "    plt.title(f'Normal Sample {i+1} Attention')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Attention Weight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_seq, y_prob_gru)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - GRU with Attention')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot precision-recall curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test_seq, y_prob_gru)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (area = {pr_auc:.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - GRU with Attention')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize threshold for better F1 score\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_prob_gru > threshold).astype(int)\n",
    "    f1 = f1_score(y_test_seq, y_pred_threshold)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Find the best threshold\n",
    "best_threshold_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_idx]\n",
    "best_f1 = f1_scores[best_threshold_idx]\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.2f} with F1 score: {best_f1:.4f}\")\n",
    "\n",
    "# Plot F1 scores for different thresholds\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, f1_scores, marker='o')\n",
    "plt.axvline(x=best_threshold, color='r', linestyle='--', label=f'Best threshold: {best_threshold:.2f}')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs. Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Recalculate metrics with the optimized threshold\n",
    "y_pred_optimized = (y_prob_gru > best_threshold).astype(int)\n",
    "accuracy_optimized = accuracy_score(y_test_seq, y_pred_optimized)\n",
    "precision_optimized = precision_score(y_test_seq, y_pred_optimized, zero_division=0)\n",
    "recall_optimized = recall_score(y_test_seq, y_pred_optimized, zero_division=0)\n",
    "f1_optimized = f1_score(y_test_seq, y_pred_optimized, zero_division=0)\n",
    "\n",
    "print(f\"Optimized Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_optimized:.4f}\")\n",
    "print(f\"Precision: {precision_optimized:.4f}\")\n",
    "print(f\"Recall: {recall_optimized:.4f}\")\n",
    "print(f\"F1 Score: {f1_optimized:.4f}\")\n",
    "\n",
    "# Plot confusion matrix with optimized threshold\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm_optimized = confusion_matrix(y_test_seq, y_pred_optimized)\n",
    "sns.heatmap(cm_optimized, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - GRU with Attention (Optimized Threshold)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}