{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI Dataset Training Data Analysis\n",
    "\n",
    "This notebook analyzes the training data patterns and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define paths\n",
    "PROCESSED_DIR = Path('../data/processed')\n",
    "MODELS_DIR = Path('../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load all processed training data\n",
    "train_files = list(PROCESSED_DIR.glob('train_*.parquet'))\n",
    "train_dfs = [pl.read_parquet(f) for f in train_files]\n",
    "\n",
    "# Combine all training data\n",
    "combined_df = pl.concat(train_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot time series patterns for each control loop\n",
    "control_loops = ['P1-PC', 'P1-LC', 'P1-FC', 'P1-TC']\n",
    "\n",
    "for loop in control_loops:\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Plot error distribution\n",
    "    error_data = combined_df.select(f'{loop}_error').to_numpy().flatten()\n",
    "    sns.histplot(error_data, kde=True, ax=axes[0])\n",
    "    axes[0].set_title(f'{loop} Error Distribution')\n",
    "    \n",
    "    # Plot moving average\n",
    "    ma_data = combined_df.select(f'{loop}_PV_mean_30').to_numpy().flatten()\n",
    "    axes[1].plot(ma_data)\n",
    "    axes[1].set_title(f'{loop} 30-point Moving Average')\n",
    "    \n",
    "    # Plot moving standard deviation\n",
    "    std_data = combined_df.select(f'{loop}_PV_std_30').to_numpy().flatten()\n",
    "    axes[2].plot(std_data)\n",
    "    axes[2].set_title(f'{loop} 30-point Moving Standard Deviation')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze correlations between different control loops\n",
    "error_cols = [f'{loop}_error' for loop in control_loops]\n",
    "ma_cols = [f'{loop}_PV_mean_30' for loop in control_loops]\n",
    "std_cols = [f'{loop}_PV_std_30' for loop in control_loops]\n",
    "\n",
    "# Create correlation matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Error correlations\n",
    "error_corr = combined_df.select(error_cols).to_pandas().corr()\n",
    "sns.heatmap(error_corr, annot=True, cmap='coolwarm', ax=axes[0])\n",
    "axes[0].set_title('Control Error Correlations')\n",
    "\n",
    "# Moving average correlations\n",
    "ma_corr = combined_df.select(ma_cols).to_pandas().corr()\n",
    "sns.heatmap(ma_corr, annot=True, cmap='coolwarm', ax=axes[1])\n",
    "axes[1].set_title('Moving Average Correlations')\n",
    "\n",
    "# Standard deviation correlations\n",
    "std_corr = combined_df.select(std_cols).to_pandas().corr()\n",
    "sns.heatmap(std_corr, annot=True, cmap='coolwarm', ax=axes[2])\n",
    "axes[2].set_title('Standard Deviation Correlations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze control variable patterns\n",
    "cv_patterns = {\n",
    "    'P1-PC': ['P1_PCV01D', 'P1_PCV02D'],\n",
    "    'P1-LC': ['P1_LCV01D'],\n",
    "    'P1-FC': ['P1_FCV03D'],\n",
    "    'P1-TC': ['P1_FCV01D', 'P1_FCV02D']\n",
    "}\n",
    "\n",
    "for loop, cvs in cv_patterns.items():\n",
    "    n_cvs = len(cvs)\n",
    "    fig, axes = plt.subplots(n_cvs, 2, figsize=(15, 5*n_cvs))\n",
    "    \n",
    "    for i, cv in enumerate(cvs):\n",
    "        # Distribution\n",
    "        cv_data = combined_df.select(cv).to_numpy().flatten()\n",
    "        sns.histplot(cv_data, kde=True, ax=axes[i,0])\n",
    "        axes[i,0].set_title(f'{cv} Distribution')\n",
    "        \n",
    "        # Time series\n",
    "        axes[i,1].plot(cv_data)\n",
    "        axes[i,1].set_title(f'{cv} Time Series')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze relationships between SP, PV, and CV\n",
    "control_vars = {\n",
    "    'P1-PC': {\n",
    "        'SP': 'P1_B2016',\n",
    "        'PV': 'P1_PIT01',\n",
    "        'CV': 'P1_PCV01D'\n",
    "    },\n",
    "    'P1-LC': {\n",
    "        'SP': 'P1_B3004',\n",
    "        'PV': 'P1_LIT01',\n",
    "        'CV': 'P1_LCV01D'\n",
    "    },\n",
    "    'P1-FC': {\n",
    "        'SP': 'P1_B3005',\n",
    "        'PV': 'P1_FT03',\n",
    "        'CV': 'P1_FCV03D'\n",
    "    },\n",
    "    'P1-TC': {\n",
    "        'SP': 'P1_B4022',\n",
    "        'PV': 'P1_TIT01',\n",
    "        'CV': 'P1_FCV01D'\n",
    "    }\n",
    "}\n",
    "\n",
    "for loop, vars in control_vars.items():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # SP vs PV\n",
    "    axes[0,0].scatter(combined_df.select(vars['SP']).to_numpy(),\n",
    "                      combined_df.select(vars['PV']).to_numpy(),\n",
    "                      alpha=0.1)\n",
    "    axes[0,0].set_title(f'{loop} SP vs PV')\n",
    "    axes[0,0].set_xlabel('Setpoint')\n",
    "    axes[0,0].set_ylabel('Process Variable')\n",
    "    \n",
    "    # Error vs CV\n",
    "    axes[0,1].scatter(combined_df.select(f'{loop}_error').to_numpy(),\n",
    "                      combined_df.select(vars['CV']).to_numpy(),\n",
    "                      alpha=0.1)\n",
    "    axes[0,1].set_title(f'{loop} Error vs CV')\n",
    "    axes[0,1].set_xlabel('Control Error')\n",
    "    axes[0,1].set_ylabel('Control Variable')\n",
    "    \n",
    "    # Time series\n",
    "    sample_df = combined_df.sample(1000)\n",
    "    axes[1,0].plot(sample_df.select(vars['SP']).to_numpy(), label='SP')\n",
    "    axes[1,0].plot(sample_df.select(vars['PV']).to_numpy(), label='PV')\n",
    "    axes[1,0].set_title(f'{loop} SP and PV Time Series')\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    axes[1,1].plot(sample_df.select(vars['CV']).to_numpy(), label='CV')\n",
    "    axes[1,1].set_title(f'{loop} CV Time Series')\n",
    "    axes[1,1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
