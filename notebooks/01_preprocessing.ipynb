{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI Dataset Preprocessing\n",
    "\n",
    "This notebook handles the preprocessing of HAI security dataset using Polars for efficient data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define paths\n",
    "DATA_DIR = Path('../hai-security-dataset')\n",
    "PROCESSED_DIR = Path('../data/processed')\n",
    "INTERIM_DIR = Path('../data/interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_dataset(version='hai-22.04'):\n",
    "    \"\"\"Load HAI dataset files using Polars lazy evaluation\"\"\"\n",
    "    version_dir = DATA_DIR / version\n",
    "    \n",
    "    # Load training files\n",
    "    train_files = list(version_dir.glob('train*.csv'))\n",
    "    train_dfs = [pl.scan_csv(f) for f in train_files]\n",
    "    \n",
    "    # Load test files\n",
    "    test_files = list(version_dir.glob('test*.csv'))\n",
    "    test_dfs = [pl.scan_csv(f) for f in test_files]\n",
    "    \n",
    "    return train_dfs, test_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def preprocess_dataframe(df):\n",
    "    \"\"\"Preprocess a single dataframe\"\"\"\n",
    "    return df.with_columns([\n",
    "        # Convert timestamp to datetime\n",
    "        pl.col('timestamp').str.to_datetime(),\n",
    "        \n",
    "        # Handle missing values\n",
    "        pl.all().fill_null(strategy='forward')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def extract_features(df):\n",
    "    \"\"\"Extract features for each control loop\"\"\"\n",
    "    control_loops = {\n",
    "        'P1-PC': {\n",
    "            'SP': 'P1_B2016',\n",
    "            'PV': 'P1_PIT01',\n",
    "            'CV': ['P1_PCV01D', 'P1_PCV02D']\n",
    "        },\n",
    "        'P1-LC': {\n",
    "            'SP': 'P1_B3004',\n",
    "            'PV': 'P1_LIT01',\n",
    "            'CV': ['P1_LCV01D']\n",
    "        },\n",
    "        'P1-FC': {\n",
    "            'SP': 'P1_B3005',\n",
    "            'PV': 'P1_FT03',\n",
    "            'CV': ['P1_FCV03D']\n",
    "        },\n",
    "        'P1-TC': {\n",
    "            'SP': 'P1_B4022',\n",
    "            'PV': 'P1_TIT01',\n",
    "            'CV': ['P1_FCV01D', 'P1_FCV02D']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for loop_name, vars in control_loops.items():\n",
    "        # Calculate control error\n",
    "        features.append(\n",
    "            (pl.col(vars['SP']) - pl.col(vars['PV'])).alias(f'{loop_name}_error')\n",
    "        )\n",
    "        \n",
    "        # Calculate moving statistics\n",
    "        window_sizes = [10, 30, 60]\n",
    "        for size in window_sizes:\n",
    "            features.extend([\n",
    "                pl.col(vars['PV']).rolling_mean(size).alias(f'{loop_name}_PV_mean_{size}'),\n",
    "                pl.col(vars['PV']).rolling_std(size).alias(f'{loop_name}_PV_std_{size}')\n",
    "            ])\n",
    "            \n",
    "            # Calculate CV statistics\n",
    "            for cv in vars['CV']:\n",
    "                features.extend([\n",
    "                    pl.col(cv).rolling_mean(size).alias(f'{cv}_mean_{size}'),\n",
    "                    pl.col(cv).rolling_std(size).alias(f'{cv}_std_{size}')\n",
    "                ])\n",
    "    \n",
    "    return df.with_columns(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def save_processed_data(df, filename, directory=PROCESSED_DIR):\n",
    "    \"\"\"Save processed dataframe to parquet format\"\"\"\n",
    "    output_path = directory / f'{filename}.parquet'\n",
    "    df.collect().write_parquet(output_path)\n",
    "    print(f'Saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load and process training data\n",
    "train_dfs, test_dfs = load_dataset()\n",
    "\n",
    "# Process each training file\n",
    "for i, df in enumerate(train_dfs):\n",
    "    processed_df = df.pipe(preprocess_dataframe).pipe(extract_features)\n",
    "    save_processed_data(processed_df, f'train_{i+1}')\n",
    "\n",
    "# Process each test file\n",
    "for i, df in enumerate(test_dfs):\n",
    "    processed_df = df.pipe(preprocess_dataframe).pipe(extract_features)\n",
    "    save_processed_data(processed_df, f'test_{i+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load a processed file to verify\n",
    "sample_df = pl.read_parquet(PROCESSED_DIR / 'train_1.parquet')\n",
    "\n",
    "# Plot some features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot control errors\n",
    "for i, loop_name in enumerate(['P1-PC', 'P1-LC', 'P1-FC', 'P1-TC']):\n",
    "    ax = axes[i//2, i%2]\n",
    "    error_col = f'{loop_name}_error'\n",
    "    \n",
    "    sample_df.select(['timestamp', error_col]).sample(1000).to_pandas().plot(\n",
    "        x='timestamp', y=error_col, ax=ax, title=f'{loop_name} Control Error'\n",
    "    )\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
