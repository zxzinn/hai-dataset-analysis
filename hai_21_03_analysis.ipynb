{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI 21.03 Dataset Analysis\n",
    "\n",
    "Analysis of the HAI 21.03 version dataset using Polars for efficient data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model, save_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Input, Dropout\n",
    "\n",
    "# Import custom preprocessing functions\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from data_preprocessing import (\n",
    "    lazy_load_csv, get_file_info, process_in_chunks, save_to_efficient_format,\n",
    "    add_time_features, add_lag_features, add_rolling_features,\n",
    "    plot_time_series, plot_correlation_matrix, plot_distribution\n",
    ")\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define dataset paths\n",
    "base_path = 'hai-security-dataset/hai-21.03/'\n",
    "train_files = [f'{base_path}train1.csv', f'{base_path}train2.csv', f'{base_path}train3.csv']\n",
    "test_files = [f'{base_path}test1.csv', f'{base_path}test2.csv', f'{base_path}test3.csv', \n",
    "              f'{base_path}test4.csv', f'{base_path}test5.csv']\n",
    "\n",
    "# Create output directory for processed data\n",
    "processed_dir = 'processed_data/hai-21.03/'\n",
    "os.makedirs(processed_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get file information\n",
    "for file_path in train_files + test_files:\n",
    "    info = get_file_info(file_path)\n",
    "    print(f\"File: {info['file_name']}\")\n",
    "    print(f\"Size: {info['file_size_mb']:.2f} MB\")\n",
    "    print(f\"Columns: {info['num_columns']}\")\n",
    "    print(f\"Estimated rows: {info['estimated_rows']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load a sample of the first training file to explore\n",
    "sample_df = pl.read_csv(train_files[0], n_rows=10000)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Number of columns: {len(sample_df.columns)}\")\n",
    "print(f\"Number of rows: {len(sample_df)}\")\n",
    "print(f\"Column names: {sample_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Identify column types\n",
    "time_column = sample_df.columns[0]  # First column is timestamp\n",
    "data_columns = sample_df.columns[1:-4]  # Middle columns are data points\n",
    "label_columns = sample_df.columns[-4:]  # Last 4 columns are attack labels\n",
    "\n",
    "print(f\"Time column: {time_column}\")\n",
    "print(f\"Number of data columns: {len(data_columns)}\")\n",
    "print(f\"Label columns: {label_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert timestamp to datetime and display sample\n",
    "sample_df = sample_df.with_column(\n",
    "    pl.col(time_column).str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    ")\n",
    "sample_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Identify new columns in HAI 21.03 compared to HAI 20.07\n",
    "# HAI 20.07 had 59 data points, HAI 21.03 has 78 data points\n",
    "# Let's find the new columns\n",
    "\n",
    "# Load a sample of HAI 20.07 data to compare\n",
    "hai_20_07_sample = pl.read_csv('hai-security-dataset/hai-20.07/train1.csv', n_rows=1)\n",
    "hai_21_03_sample = sample_df\n",
    "\n",
    "# Get column names\n",
    "hai_20_07_cols = set(hai_20_07_sample.columns)\n",
    "hai_21_03_cols = set(hai_21_03_sample.columns)\n",
    "\n",
    "# Find new columns\n",
    "new_cols = hai_21_03_cols - hai_20_07_cols\n",
    "print(f\"New columns in HAI 21.03: {sorted(list(new_cols))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot time series for key process variables\n",
    "key_vars = ['P1_PIT01', 'P1_TIT01', 'P1_LIT01', 'P2_SIT01']\n",
    "plot_time_series(sample_df, time_column, key_vars, title='Key Process Variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot time series for new variables\n",
    "new_vars = [col for col in new_cols if col not in label_columns and col != time_column]\n",
    "if len(new_vars) > 4:\n",
    "    new_vars = new_vars[:4]  # Limit to 4 for better visualization\n",
    "    \n",
    "plot_time_series(sample_df, time_column, new_vars, title='New Variables in HAI 21.03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot correlation matrix for key variables\n",
    "corr_vars = key_vars + ['P1_FT01Z', 'P1_FT02Z', 'P1_FT03Z']\n",
    "plot_correlation_matrix(sample_df, columns=corr_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot distributions of key variables\n",
    "plot_distribution(sample_df, key_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load a sample of test data to visualize attacks\n",
    "test_sample_df = pl.read_csv(test_files[0], n_rows=10000).with_column(\n",
    "    pl.col(time_column).str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S\")\n",
    ")\n",
    "\n",
    "# Plot time series with attack regions highlighted\n",
    "plot_time_series(test_sample_df, time_column, key_vars, \n",
    "                 title='Process Variables During Attacks', \n",
    "                 attack_column='attack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def preprocess_dataset(file_path, output_path=None, is_training=True):\n",
    "    \"\"\"\n",
    "    Preprocess a dataset file with feature engineering\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file\n",
    "        output_path (str): Path to save the processed file\n",
    "        is_training (bool): Whether this is a training dataset\n",
    "        \n",
    "    Returns:\n",
    "        pl.DataFrame: Processed DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"Processing {file_path}...\")\n",
    "    \n",
    "    # Lazy load the dataset\n",
    "    df_lazy = lazy_load_csv(file_path)\n",
    "    \n",
    "    # Add time features\n",
    "    df_lazy = add_time_features(df_lazy)\n",
    "    \n",
    "    # Collect the data (we'll need it for lag features)\n",
    "    print(\"Collecting data...\")\n",
    "    df = df_lazy.collect()\n",
    "    \n",
    "    # Identify column types\n",
    "    time_column = df.columns[0]  # First column is timestamp\n",
    "    data_columns = df.columns[1:-4]  # Middle columns are data points\n",
    "    label_columns = df.columns[-4:]  # Last 4 columns are attack labels\n",
    "    \n",
    "    # Select key process variables for feature engineering\n",
    "    # Include both common variables and new variables specific to HAI 21.03\n",
    "    key_vars = ['P1_PIT01', 'P1_TIT01', 'P1_LIT01', 'P1_FT01Z', 'P1_FT02Z', 'P1_FT03Z', 'P2_SIT01',\n",
    "                'P1_PP01AR', 'P1_PP01BR', 'P1_PP02R', 'P2_SCO', 'P2_SCST', 'P4_ST_GOV']\n",
    "    \n",
    "    # Add lag features for key variables\n",
    "    print(\"Adding lag features...\")\n",
    "    df = add_lag_features(df, key_vars, lags=[1, 5, 10, 30])\n",
    "    \n",
    "    # Add rolling window features for key variables\n",
    "    print(\"Adding rolling window features...\")\n",
    "    df = add_rolling_features(df, key_vars, windows=[5, 10, 30])\n",
    "    \n",
    "    # Save to efficient format if output_path is provided\n",
    "    if output_path:\n",
    "        save_to_efficient_format(df, output_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process training datasets\n",
    "train_dfs = []\n",
    "for i, file_path in enumerate(train_files):\n",
    "    output_path = f\"{processed_dir}train{i+1}.parquet\"\n",
    "    df = preprocess_dataset(file_path, output_path, is_training=True)\n",
    "    train_dfs.append(df)\n",
    "\n",
    "# Combine training datasets\n",
    "train_df = pl.concat(train_dfs)\n",
    "print(f\"Combined training data shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process test datasets\n",
    "test_dfs = []\n",
    "for i, file_path in enumerate(test_files):\n",
    "    output_path = f\"{processed_dir}test{i+1}.parquet\"\n",
    "    df = preprocess_dataset(file_path, output_path, is_training=False)\n",
    "    test_dfs.append(df)\n",
    "\n",
    "# Combine test datasets\n",
    "test_df = pl.concat(test_dfs)\n",
    "print(f\"Combined test data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def prepare_model_data(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Prepare data for modeling by selecting features and scaling\n",
    "    \n",
    "    Args:\n",
    "        train_df (pl.DataFrame): Training DataFrame\n",
    "        test_df (pl.DataFrame): Test DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (X_train, X_test, y_test, scaler)\n",
    "    \"\"\"\n",
    "    # Identify column types\n",
    "    time_column = train_df.columns[0]  # First column is timestamp\n",
    "    data_columns = [col for col in train_df.columns if col not in [time_column, 'hour', 'day_of_week', \n",
    "                                                                   'day', 'month', 'year', 'is_weekend', \n",
    "                                                                   'time_of_day', 'attack', 'attack_P1', \n",
    "                                                                   'attack_P2', 'attack_P3']]\n",
    "    \n",
    "    # Select only numeric columns\n",
    "    numeric_cols = [col for col in data_columns if train_df[col].dtype in [pl.Float32, pl.Float64, pl.Int32, pl.Int64]]\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X_train = train_df.select(numeric_cols).to_numpy()\n",
    "    X_test = test_df.select(numeric_cols).to_numpy()\n",
    "    \n",
    "    # Get attack labels for test data\n",
    "    y_test = test_df.select('attack').to_numpy().flatten()\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Save the scaler\n",
    "    with open(f\"{processed_dir}scaler.pkl\", 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    # Save feature names\n",
    "    with open(f\"{processed_dir}feature_names.pkl\", 'wb') as f:\n",
    "        pickle.dump(numeric_cols, f)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_test, scaler, numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare data for modeling\n",
    "X_train, X_test, y_test, scaler, feature_names = prepare_model_data(train_df, test_df)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"Number of features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Anomaly Detection Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train Isolation Forest model\n",
    "print(\"Training Isolation Forest model...\")\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.01, random_state=42, n_jobs=-1)\n",
    "iso_forest.fit(X_train)\n",
    "\n",
    "# Save the model\n",
    "with open(f\"{processed_dir}isolation_forest_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(iso_forest, f)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_if = iso_forest.predict(X_test)\n",
    "# Convert predictions to binary (1 for inlier, -1 for outlier)\n",
    "y_pred_if_binary = np.where(y_pred_if == 1, 0, 1)  # 0 for normal, 1 for anomaly\n",
    "\n",
    "# Calculate anomaly scores\n",
    "anomaly_scores_if = iso_forest.score_samples(X_test)\n",
    "# Invert scores (lower score = more anomalous)\n",
    "anomaly_scores_if = -anomaly_scores_if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate Isolation Forest model\n",
    "print(\"Isolation Forest Results:\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_if_binary))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_if_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot ROC curve for Isolation Forest\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr_if, tpr_if, thresholds_if = roc_curve(y_test, anomaly_scores_if)\n",
    "roc_auc_if = auc(fpr_if, tpr_if)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_if, tpr_if, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_if:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Isolation Forest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot Precision-Recall curve for Isolation Forest\n",
    "precision_if, recall_if, _ = precision_recall_curve(y_test, anomaly_scores_if)\n",
    "pr_auc_if = auc(recall_if, precision_if)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall_if, precision_if, color='darkorange', lw=2, label=f'PR curve (area = {pr_auc_if:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - Isolation Forest')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare data for autoencoder\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        xs.append(x)\n",
    "    return np.array(xs)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 30\n",
    "\n",
    "# Create sequences\n",
    "X_train_seq = create_sequences(X_train, seq_length)\n",
    "X_test_seq = create_sequences(X_test, seq_length)\n",
    "\n",
    "# Adjust y_test to match sequence length\n",
    "y_test_seq = y_test[seq_length:]\n",
    "\n",
    "print(f\"X_train_seq shape: {X_train_seq.shape}\")\n",
    "print(f\"X_test_seq shape: {X_test_seq.shape}\")\n",
    "print(f\"y_test_seq shape: {y_test_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Build LSTM Autoencoder model\n",
    "def build_lstm_autoencoder(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(128, activation='relu', input_shape=input_shape, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(64, activation='relu', return_sequences=False),\n",
    "        RepeatVector(input_shape[0]),\n",
    "        LSTM(64, activation='relu', return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(128, activation='relu', return_sequences=True),\n",
    "        TimeDistributed(Dense(input_shape[1]))\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])\n",
    "lstm_autoencoder = build_lstm_autoencoder(input_shape)\n",
    "lstm_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model\n",
    "history = lstm_autoencoder.fit(\n",
    "    X_train_seq, X_train_seq,\n",
    "    epochs=15,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min', restore_best_weights=True)\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the model\n",
    "lstm_autoencoder.save(f\"{processed_dir}lstm_autoencoder_model\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Predict on test data\n",
    "X_test_pred = lstm_autoencoder.predict(X_test_seq)\n",
    "\n",
    "# Calculate MSE for each sample\n",
    "mse = np.mean(np.square(X_test_seq - X_test_pred), axis=(1, 2))\n",
    "\n",
    "# Plot MSE distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(mse, bins=50)\n",
    "plt.title('MSE Distribution')\n",
    "plt.xlabel('MSE')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Find threshold for anomaly detection\n",
    "threshold = np.percentile(mse, 95)  # 95th percentile\n",
    "print(f\"Threshold: {threshold}\")\n",
    "\n",
    "# Classify anomalies\n",
    "y_pred_ae = (mse > threshold).astype(int)\n",
    "\n",
    "# Evaluate autoencoder model\n",
    "print(\"Autoencoder Results:\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_seq, y_pred_ae))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_seq, y_pred_ae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot ROC curve for Autoencoder\n",
    "fpr_ae, tpr_ae, thresholds_ae = roc_curve(y_test_seq, mse)\n",
    "roc_auc_ae = auc(fpr_ae, tpr_ae)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_ae, tpr_ae, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_ae:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - LSTM Autoencoder')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot Precision-Recall curve for Autoencoder\n",
    "precision_ae, recall_ae, _ = precision_recall_curve(y_test_seq, mse)\n",
    "pr_auc_ae = auc(recall_ae, precision_ae)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall_ae, precision_ae, color='darkorange', lw=2, label=f'PR curve (area = {pr_auc_ae:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - LSTM Autoencoder')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Anomaly Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a DataFrame with timestamps, actual labels, and predictions\n",
    "results_df = pl.DataFrame({\n",
    "    'timestamp': test_df.slice(seq_length).select('timestamp').to_series(),\n",
    "    'actual': y_test_seq,\n",
    "    'pred_isolation_forest': y_pred_if_binary[seq_length:],\n",
    "    'pred_autoencoder': y_pred_ae,\n",
    "    'score_isolation_forest': anomaly_scores_if[seq_length:],\n",
    "    'score_autoencoder': mse\n",
    "})\n",
    "\n",
    "# Plot time series of anomaly scores\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot Isolation Forest scores\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(results_df['timestamp'].to_numpy(), results_df['score_isolation_forest'].to_numpy(), label='Anomaly Score')\n",
    "plt.scatter(results_df.filter(pl.col('actual') > 0)['timestamp'].to_numpy(), \n",
    "           results_df.filter(pl.col('actual') > 0)['score_isolation_forest'].to_numpy(), \n",
    "           color='red', label='Actual Anomaly')\n",
    "plt.title('Isolation Forest Anomaly Scores')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Autoencoder scores\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(results_df['timestamp'].to_numpy(), results_df['score_autoencoder'].to_numpy(), label='Anomaly Score')\n",
    "plt.scatter(results_df.filter(pl.col('actual') > 0)['timestamp'].to_numpy(), \n",
    "           results_df.filter(pl.col('actual') > 0)['score_autoencoder'].to_numpy(), \n",
    "           color='red', label='Actual Anomaly')\n",
    "plt.axhline(y=threshold, color='green', linestyle='--', label=f'Threshold ({threshold:.4f})')\n",
    "plt.title('Autoencoder Reconstruction Error (MSE)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare model performance\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.plot(fpr_if[seq_length:], tpr_if[seq_length:], label=f'Isolation Forest (AUC = {roc_auc_if:.2f})')\n",
    "plt.plot(fpr_ae, tpr_ae, label=f'LSTM Autoencoder (AUC = {roc_auc_ae:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze feature importance for Isolation Forest\n",
    "def get_feature_importance(model, feature_names):\n",
    "    \"\"\"\n",
    "    Get feature importance from Isolation Forest model\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Isolation Forest model\n",
    "        feature_names: List of feature names\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with feature importance\n",
    "    \"\"\"\n",
    "    # Get feature importance\n",
    "    importances = np.mean([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    importance_df = pl.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = importance_df.sort('importance', descending=True)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Get feature importance\n",
    "importance_df = get_feature_importance(iso_forest, feature_names)\n",
    "\n",
    "# Plot top 20 features\n",
    "top_features = importance_df.head(20)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(top_features['feature'].to_numpy(), top_features['importance'].to_numpy())\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Important Features')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show most important at the top\n",
    "plt.grid(True, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save results to CSV\n",
    "results_df.write_csv(f\"{processed_dir}anomaly_detection_results.csv\")\n",
    "\n",
    "# Save feature importance\n",
    "importance_df.write_csv(f\"{processed_dir}feature_importance.csv\")\n",
    "\n",
    "# Save model performance metrics\n",
    "performance_metrics = {\n",
    "    'isolation_forest_roc_auc': roc_auc_if,\n",
    "    'isolation_forest_pr_auc': pr_auc_if,\n",
    "    'autoencoder_roc_auc': roc_auc_ae,\n",
    "    'autoencoder_pr_auc': pr_auc_ae,\n",
    "    'autoencoder_threshold': threshold\n",
    "}\n",
    "\n",
    "with open(f\"{processed_dir}model_performance.pkl\", 'wb') as f:\n",
    "    pickle.dump(performance_metrics, f)\n",
    "\n",
    "print(\"Results saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
