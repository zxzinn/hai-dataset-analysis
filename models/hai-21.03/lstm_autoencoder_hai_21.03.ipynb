{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI-21.03 Dataset Anomaly Detection - LSTM Autoencoder Model\n",
    "\n",
    "This notebook uses an LSTM Autoencoder for anomaly detection on the HAI-21.03 dataset.\n",
    "\n",
    "The HAI dataset contains data from industrial control systems (ICS), where training data does not include attack labels, while test data includes attack labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Import deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential, load_model, save_model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, Dense, Dropout, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Import preprocessing libraries\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, auc, roc_curve, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data path\n",
    "data_path = \"../../hai-security-dataset/hai-21.03/\"\n",
    "\n",
    "# Load training data\n",
    "train_files = [f for f in os.listdir(data_path) if f.startswith('train')]\n",
    "train_dfs = []\n",
    "\n",
    "for file in train_files:\n",
    "    print(f\"Loading training file: {file}\")\n",
    "    df = pd.read_csv(f\"{data_path}{file}\", sep=\",\")\n",
    "    train_dfs.append(df)\n",
    "    \n",
    "# Combine training data\n",
    "train_df = pd.concat(train_dfs, ignore_index=True)\n",
    "print(f\"Training data shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_files = [f for f in os.listdir(data_path) if f.startswith('test')]\n",
    "test_dfs = []\n",
    "\n",
    "for file in test_files:\n",
    "    print(f\"Loading test file: {file}\")\n",
    "    df = pd.read_csv(f\"{data_path}{file}\", sep=\",\")\n",
    "    test_dfs.append(df)\n",
    "    \n",
    "# Combine test data\n",
    "test_df = pd.concat(test_dfs, ignore_index=True)\n",
    "print(f\"Test data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic information of the dataset\n",
    "print(\"Column names in training dataset:\")\n",
    "print(train_df.columns.tolist())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in training dataset:\")\n",
    "print(train_df.isnull().sum().sum())\n",
    "\n",
    "print(\"\\nMissing values in test dataset:\")\n",
    "print(test_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime\n",
    "train_df['time'] = pd.to_datetime(train_df['time'])\n",
    "test_df['time'] = pd.to_datetime(test_df['time'])\n",
    "\n",
    "# Extract attack labels from test data\n",
    "attack_columns = [col for col in test_df.columns if 'attack' in col.lower()]\n",
    "print(f\"Attack label columns: {attack_columns}\")\n",
    "\n",
    "# Create a combined attack label (if multiple attack columns exist)\n",
    "if len(attack_columns) > 1:\n",
    "    test_df['attack_combined'] = test_df[attack_columns].max(axis=1)\n",
    "    y_test = test_df['attack_combined']\n",
    "else:\n",
    "    y_test = test_df[attack_columns[0]]\n",
    "\n",
    "# Print attack distribution\n",
    "print(f\"\\nAttack distribution in test data:\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training and testing\n",
    "# Exclude timestamp and attack labels\n",
    "feature_columns = [col for col in train_df.columns if col not in ['time'] + attack_columns]\n",
    "print(f\"Number of features: {len(feature_columns)}\")\n",
    "\n",
    "# Prepare training and testing data\n",
    "X_train_raw = train_df[feature_columns].values\n",
    "X_test_raw = test_df[feature_columns].values\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "X_test_scaled = scaler.transform(X_test_raw)\n",
    "\n",
    "print(f\"Training data shape after preprocessing: {X_train_scaled.shape}\")\n",
    "print(f\"Testing data shape after preprocessing: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Sequences for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequence = data[i:i+seq_length]\n",
    "        sequences.append(sequence)\n",
    "    return np.array(sequences)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 30  # 30 time steps (can be adjusted based on the temporal patterns in the data)\n",
    "\n",
    "# Create sequences for training data\n",
    "X_train_seq = create_sequences(X_train_scaled, seq_length)\n",
    "print(f\"Training sequences shape: {X_train_seq.shape}\")\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "X_train_lstm, X_val_lstm = train_test_split(X_train_seq, test_size=0.2, random_state=42)\n",
    "print(f\"LSTM training data shape: {X_train_lstm.shape}\")\n",
    "print(f\"LSTM validation data shape: {X_val_lstm.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build LSTM Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "input_dim = X_train_seq.shape[2]  # Number of features\n",
    "timesteps = X_train_seq.shape[1]  # Sequence length\n",
    "latent_dim = 32  # Size of the latent space\n",
    "\n",
    "# Build the LSTM Autoencoder model\n",
    "def build_lstm_autoencoder(input_dim, timesteps, latent_dim):\n",
    "    # Encoder\n",
    "    inputs = Input(shape=(timesteps, input_dim))\n",
    "    encoded = LSTM(64, return_sequences=True)(inputs)\n",
    "    encoded = LSTM(latent_dim, return_sequences=False)(encoded)\n",
    "    \n",
    "    # Decoder\n",
    "    decoded = RepeatVector(timesteps)(encoded)\n",
    "    decoded = LSTM(latent_dim, return_sequences=True)(decoded)\n",
    "    decoded = LSTM(64, return_sequences=True)(decoded)\n",
    "    decoded = TimeDistributed(Dense(input_dim))(decoded)\n",
    "    \n",
    "    # Autoencoder model\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    \n",
    "    # Encoder model (for extracting the latent representation)\n",
    "    encoder = Model(inputs, encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "# Create the model\n",
    "autoencoder, encoder = build_lstm_autoencoder(input_dim, timesteps, latent_dim)\n",
    "\n",
    "# Print model summary\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "model_dir = \"./\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = os.path.join(model_dir, \"lstm_autoencoder_model.h5\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training LSTM Autoencoder model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    X_train_lstm, X_train_lstm,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val_lstm, X_val_lstm),\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the Model and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaler\n",
    "scaler_filename = os.path.join(model_dir, \"scaler.pkl\")\n",
    "with open(scaler_filename, 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "    \n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Scaler saved to {scaler_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for test data\n",
    "# We need to handle the fact that we need labels for each sequence\n",
    "X_test_seq = []\n",
    "y_test_seq = []\n",
    "\n",
    "for i in range(len(X_test_scaled) - seq_length):\n",
    "    X_test_seq.append(X_test_scaled[i:i+seq_length])\n",
    "    # Use the label of the last timestep in the sequence\n",
    "    y_test_seq.append(y_test.iloc[i+seq_length-1])\n",
    "\n",
    "X_test_seq = np.array(X_test_seq)\n",
    "y_test_seq = np.array(y_test_seq)\n",
    "\n",
    "print(f\"Test sequences shape: {X_test_seq.shape}\")\n",
    "print(f\"Test labels shape: {y_test_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "print(\"Predicting on test data...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Get reconstructions\n",
    "X_test_pred = autoencoder.predict(X_test_seq)\n",
    "\n",
    "prediction_time = time.time() - start_time\n",
    "print(f\"Prediction completed in {prediction_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate reconstruction error (MSE) for each sequence\n",
    "mse = np.mean(np.square(X_test_seq - X_test_pred), axis=(1, 2))\n",
    "\n",
    "# Plot reconstruction error distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(mse, bins=50, alpha=0.7)\n",
    "plt.title('Reconstruction Error Distribution')\n",
    "plt.xlabel('Reconstruction Error (MSE)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstruction error by class\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(mse[y_test_seq == 0], bins=50, alpha=0.7, label='Normal', color='blue')\n",
    "plt.hist(mse[y_test_seq == 1], bins=50, alpha=0.7, label='Anomaly', color='red')\n",
    "plt.title('Reconstruction Error by Class')\n",
    "plt.xlabel('Reconstruction Error (MSE)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different thresholds for anomaly detection\n",
    "thresholds = np.linspace(min(mse), max(mse), 100)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = np.where(mse >= threshold, 1, 0)\n",
    "    f1_scores.append(f1_score(y_test_seq, y_pred_threshold))\n",
    "    precision_scores.append(precision_score(y_test_seq, y_pred_threshold))\n",
    "    recall_scores.append(recall_score(y_test_seq, y_pred_threshold))\n",
    "\n",
    "# Find the threshold that maximizes F1 score\n",
    "best_threshold_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_idx]\n",
    "best_f1 = f1_scores[best_threshold_idx]\n",
    "best_precision = precision_scores[best_threshold_idx]\n",
    "best_recall = recall_scores[best_threshold_idx]\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.4f}\")\n",
    "print(f\"Best F1 score: {best_f1:.4f}\")\n",
    "print(f\"Precision at best threshold: {best_precision:.4f}\")\n",
    "print(f\"Recall at best threshold: {best_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot F1, precision, and recall scores for different thresholds\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(thresholds, f1_scores, 'b-', label='F1 Score')\n",
    "plt.plot(thresholds, precision_scores, 'g-', label='Precision')\n",
    "plt.plot(thresholds, recall_scores, 'r-', label='Recall')\n",
    "plt.axvline(x=best_threshold, color='k', linestyle='--', label=f'Best Threshold: {best_threshold:.4f}')\n",
    "plt.title('Performance Metrics vs. Threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the optimized threshold\n",
    "y_pred_optimized = np.where(mse >= best_threshold, 1, 0)\n",
    "\n",
    "# Evaluate with optimized threshold\n",
    "print(\"Confusion Matrix with Optimized Threshold:\")\n",
    "cm_optimized = confusion_matrix(y_test_seq, y_pred_optimized)\n",
    "print(cm_optimized)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_optimized, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Normal', 'Anomaly'],\n",
    "            yticklabels=['Normal', 'Anomaly'])\n",
    "plt.title('Confusion Matrix with Optimized Threshold')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report with Optimized Threshold:\")\n",
    "print(classification_report(y_test_seq, y_pred_optimized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ROC and Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test_seq, mse)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curve\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test_seq, mse)\n",
    "pr_auc = auc(recall_curve, precision_curve)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall_curve, precision_curve, color='blue', lw=2, label=f'PR curve (area = {pr_auc:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Analyze Anomalies Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with timestamps, actual labels, and predictions\n",
    "# We need to adjust the timestamps to match the sequence structure\n",
    "timestamps = test_df['time'].iloc[seq_length-1:len(X_test_seq)+seq_length-1].values\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'timestamp': timestamps,\n",
    "    'actual': y_test_seq,\n",
    "    'predicted': y_pred_optimized,\n",
    "    'reconstruction_error': mse\n",
    "})\n",
    "\n",
    "# Plot actual vs predicted anomalies over time\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Sample data for better visualization if dataset is large\n",
    "sample_size = min(10000, len(results_df))\n",
    "sample_indices = np.linspace(0, len(results_df)-1, sample_size, dtype=int)\n",
    "sample_df = results_df.iloc[sample_indices]\n",
    "\n",
    "plt.plot(sample_df['timestamp'], sample_df['actual'], 'b-', alpha=0.5, label='Actual')\n",
    "plt.plot(sample_df['timestamp'], sample_df['predicted'], 'r-', alpha=0.5, label='Predicted')\n",
    "plt.title('Actual vs Predicted Anomalies Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly (1) / Normal (0)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstruction error over time with actual labels\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Create a colormap based on actual labels\n",
    "colors = np.where(sample_df['actual'] == 1, 'red', 'blue')\n",
    "\n",
    "plt.scatter(sample_df['timestamp'], sample_df['reconstruction_error'], c=colors, alpha=0.5, s=10)\n",
    "plt.title('Reconstruction Error Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a horizontal line at the threshold\n",
    "plt.axhline(y=best_threshold, color='g', linestyle='--')\n",
    "\n",
    "# Add a legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Actual Anomaly'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Normal'),\n",
    "    Line2D([0], [0], color='g', linestyle='--', label='Threshold')\n",
    "]\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save the Optimized Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized threshold\n",
    "threshold_filename = os.path.join(model_dir, \"optimized_threshold.pkl\")\n",
    "with open(threshold_filename, 'wb') as file:\n",
    "    pickle.dump(best_threshold, file)\n",
    "    \n",
    "print(f\"Optimized threshold saved to {threshold_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Conclusion\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Loaded and preprocessed the HAI-21.03 dataset\n",
    "2. Created sequences for LSTM processing\n",
    "3. Built and trained an LSTM Autoencoder model for anomaly detection\n",
    "4. Evaluated the model's performance using reconstruction error\n",
    "5. Optimized the anomaly detection threshold to maximize F1 score\n",
    "6. Saved the model, scaler, and optimized threshold for future use\n",
    "\n",
    "The LSTM Autoencoder has demonstrated its ability to detect anomalies in time series data from industrial control systems by learning the normal patterns in the data and identifying deviations from these patterns as potential anomalies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}