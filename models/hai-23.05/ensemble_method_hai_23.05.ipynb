{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI-23.05 Dataset Anomaly Detection - Ensemble Method\n",
    "\n",
    "This notebook uses an ensemble of multiple anomaly detection methods for the HAI-23.05 dataset.\n",
    "\n",
    "The HAI dataset contains data from industrial control systems (ICS), where training data does not include attack labels, while test data includes attack labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, auc, roc_curve, f1_score, precision_score, recall_score\n",
    "\n",
    "# Import deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data path\n",
    "data_path = \"../../hai-security-dataset/hai-23.05/\"\n",
    "\n",
    "# Load training data\n",
    "train_files = [f for f in os.listdir(data_path) if f.startswith('hai-train')]\n",
    "train_dfs = []\n",
    "\n",
    "for file in train_files:\n",
    "    print(f\"Loading training file: {file}\")\n",
    "    df = pd.read_csv(f\"{data_path}{file}\")\n",
    "    train_dfs.append(df)\n",
    "    \n",
    "# Combine training data\n",
    "train_df = pd.concat(train_dfs, ignore_index=True)\n",
    "print(f\"Training data shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_files = [f for f in os.listdir(data_path) if f.startswith('hai-test')]\n",
    "test_dfs = []\n",
    "\n",
    "for file in test_files:\n",
    "    print(f\"Loading test file: {file}\")\n",
    "    df = pd.read_csv(f\"{data_path}{file}\")\n",
    "    test_dfs.append(df)\n",
    "    \n",
    "# Combine test data\n",
    "test_df = pd.concat(test_dfs, ignore_index=True)\n",
    "print(f\"Test data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load label data\n",
    "label_files = [f for f in os.listdir(data_path) if f.startswith('label-test')]\n",
    "label_dfs = []\n",
    "\n",
    "for file, test_file in zip(label_files, test_files):\n",
    "    print(f\"Loading label file: {file} for test file: {test_file}\")\n",
    "    df = pd.read_csv(f\"{data_path}{file}\")\n",
    "    label_dfs.append(df)\n",
    "    \n",
    "# Combine label data\n",
    "label_df = pd.concat(label_dfs, ignore_index=True)\n",
    "print(f\"Label data shape: {label_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic information of the dataset\n",
    "print(\"Column names in training dataset:\")\n",
    "print(train_df.columns.tolist())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in training dataset:\")\n",
    "print(train_df.isnull().sum().sum())\n",
    "\n",
    "print(\"\\nMissing values in test dataset:\")\n",
    "print(test_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime\n",
    "train_df['timestamp'] = pd.to_datetime(train_df['timestamp'])\n",
    "test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "\n",
    "# Check label data structure\n",
    "print(\"Label data columns:\")\n",
    "print(label_df.columns.tolist())\n",
    "\n",
    "# Merge test data with labels\n",
    "if 'timestamp' in label_df.columns:\n",
    "    label_df['timestamp'] = pd.to_datetime(label_df['timestamp'])\n",
    "    test_with_labels = pd.merge(test_df, label_df, on='timestamp', how='left')\n",
    "else:\n",
    "    # If there's no timestamp in label_df, assume the order matches test_df\n",
    "    test_with_labels = test_df.copy()\n",
    "    for col in label_df.columns:\n",
    "        test_with_labels[col] = label_df[col].values\n",
    "\n",
    "# Extract attack labels\n",
    "attack_columns = [col for col in test_with_labels.columns if 'attack' in col.lower()]\n",
    "print(f\"Attack label columns: {attack_columns}\")\n",
    "\n",
    "# Create a combined attack label (if multiple attack columns exist)\n",
    "if len(attack_columns) > 1:\n",
    "    test_with_labels['attack_combined'] = test_with_labels[attack_columns].max(axis=1)\n",
    "    y_test = test_with_labels['attack_combined']\n",
    "else:\n",
    "    y_test = test_with_labels[attack_columns[0]]\n",
    "\n",
    "# Print attack distribution\n",
    "print(f\"\\nAttack distribution in test data:\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training and testing\n",
    "# Exclude timestamp and attack labels\n",
    "feature_columns = [col for col in train_df.columns if col not in ['timestamp'] + attack_columns]\n",
    "print(f\"Number of features: {len(feature_columns)}\")\n",
    "\n",
    "# Prepare training and testing data\n",
    "X_train = train_df[feature_columns].values\n",
    "X_test = test_df[feature_columns].values\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training data shape after preprocessing: {X_train_scaled.shape}\")\n",
    "print(f\"Testing data shape after preprocessing: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement Individual Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Isolation Forest model\n",
    "print(\"Training Isolation Forest model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    max_samples='auto',\n",
    "    contamination='auto',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "iso_forest.fit(X_train_scaled)\n",
    "\n",
    "# Get anomaly scores (-1 for anomalies, 1 for normal)\n",
    "iso_forest_scores_train = iso_forest.decision_function(X_train_scaled)\n",
    "iso_forest_scores_test = iso_forest.decision_function(X_test_scaled)\n",
    "\n",
    "# Convert to anomaly scores (higher score = more anomalous)\n",
    "iso_forest_anomaly_scores_train = -iso_forest_scores_train\n",
    "iso_forest_anomaly_scores_test = -iso_forest_scores_test\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Isolation Forest training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Local Outlier Factor model\n",
    "print(\"Training Local Outlier Factor model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=20,\n",
    "    contamination='auto',\n",
    "    novelty=True,  # Enable predict method\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lof.fit(X_train_scaled)\n",
    "\n",
    "# Get anomaly scores (-1 for anomalies, 1 for normal)\n",
    "lof_scores_train = lof.decision_function(X_train_scaled)\n",
    "lof_scores_test = lof.decision_function(X_test_scaled)\n",
    "\n",
    "# Convert to anomaly scores (higher score = more anomalous)\n",
    "lof_anomaly_scores_train = -lof_scores_train\n",
    "lof_anomaly_scores_test = -lof_scores_test\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Local Outlier Factor training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train One-Class SVM model\n",
    "print(\"Training One-Class SVM model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "ocsvm = OneClassSVM(\n",
    "    kernel='rbf',\n",
    "    gamma='scale',\n",
    "    nu=0.01  # Approximate proportion of outliers\n",
    ")\n",
    "\n",
    "ocsvm.fit(X_train_scaled)\n",
    "\n",
    "# Get anomaly scores (-1 for anomalies, 1 for normal)\n",
    "ocsvm_scores_train = ocsvm.decision_function(X_train_scaled)\n",
    "ocsvm_scores_test = ocsvm.decision_function(X_test_scaled)\n",
    "\n",
    "# Convert to anomaly scores (higher score = more anomalous)\n",
    "ocsvm_anomaly_scores_train = -ocsvm_scores_train\n",
    "ocsvm_anomaly_scores_test = -ocsvm_scores_test\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"One-Class SVM training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 PCA with Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "print(\"Applying PCA...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# First, fit PCA with all components to determine the number of components to retain\n",
    "pca_all = PCA()\n",
    "pca_all.fit(X_train_scaled)\n",
    "\n",
    "# Find number of components for 95% variance\n",
    "n_components_95 = np.argmax(np.cumsum(pca_all.explained_variance_ratio_) >= 0.95) + 1\n",
    "print(f\"Number of components for 95% variance: {n_components_95}\")\n",
    "\n",
    "# Apply PCA with the selected number of components\n",
    "pca = PCA(n_components=n_components_95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Estimate the covariance matrix from the PCA-transformed training data\n",
    "cov = EmpiricalCovariance().fit(X_train_pca)\n",
    "\n",
    "# Calculate the mean of the PCA-transformed training data\n",
    "mean_vec = np.mean(X_train_pca, axis=0)\n",
    "\n",
    "# Function to calculate Mahalanobis distance\n",
    "def mahalanobis_distance(x, mean, cov):\n",
    "    inv_cov = np.linalg.inv(cov.covariance_)\n",
    "    x_minus_mean = x - mean\n",
    "    left = np.dot(x_minus_mean, inv_cov)\n",
    "    mahal = np.dot(left, x_minus_mean.T)\n",
    "    return np.sqrt(mahal.diagonal())\n",
    "\n",
    "# Calculate Mahalanobis distance for training and test data\n",
    "mahal_scores_train = mahalanobis_distance(X_train_pca, mean_vec, cov)\n",
    "mahal_scores_test = mahalanobis_distance(X_test_pca, mean_vec, cov)\n",
    "\n",
    "# Mahalanobis distance is already an anomaly score (higher = more anomalous)\n",
    "mahal_anomaly_scores_train = mahal_scores_train\n",
    "mahal_anomaly_scores_test = mahal_scores_test\n",
    "\n",
    "pca_time = time.time() - start_time\n",
    "print(f\"PCA and Mahalanobis distance calculation completed in {pca_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train Autoencoder model\n",
    "print(\"Building and training Autoencoder model...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Define model parameters\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "encoding_dim = 32\n",
    "hidden_dim = 64\n",
    "\n",
    "# Build the autoencoder model\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "# Encoder\n",
    "encoded = Dense(hidden_dim, activation='relu')(input_layer)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "# Decoder\n",
    "decoded = Dense(hidden_dim, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = autoencoder.fit(\n",
    "    X_train_scaled, X_train_scaled,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Get reconstructions\n",
    "X_train_reconstructed = autoencoder.predict(X_train_scaled)\n",
    "X_test_reconstructed = autoencoder.predict(X_test_scaled)\n",
    "\n",
    "# Calculate reconstruction error (MSE) for each sample\n",
    "autoencoder_mse_train = np.mean(np.square(X_train_scaled - X_train_reconstructed), axis=1)\n",
    "autoencoder_mse_test = np.mean(np.square(X_test_scaled - X_test_reconstructed), axis=1)\n",
    "\n",
    "# MSE is already an anomaly score (higher = more anomalous)\n",
    "autoencoder_anomaly_scores_train = autoencoder_mse_train\n",
    "autoencoder_anomaly_scores_test = autoencoder_mse_test\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Autoencoder training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Normalize Anomaly Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize scores to [0, 1] range\n",
    "def normalize_scores(scores):\n",
    "    min_val = np.min(scores)\n",
    "    max_val = np.max(scores)\n",
    "    return (scores - min_val) / (max_val - min_val)\n",
    "\n",
    "# Normalize all anomaly scores\n",
    "iso_forest_norm_train = normalize_scores(iso_forest_anomaly_scores_train)\n",
    "iso_forest_norm_test = normalize_scores(iso_forest_anomaly_scores_test)\n",
    "\n",
    "lof_norm_train = normalize_scores(lof_anomaly_scores_train)\n",
    "lof_norm_test = normalize_scores(lof_anomaly_scores_test)\n",
    "\n",
    "ocsvm_norm_train = normalize_scores(ocsvm_anomaly_scores_train)\n",
    "ocsvm_norm_test = normalize_scores(ocsvm_anomaly_scores_test)\n",
    "\n",
    "mahal_norm_train = normalize_scores(mahal_anomaly_scores_train)\n",
    "mahal_norm_test = normalize_scores(mahal_anomaly_scores_test)\n",
    "\n",
    "autoencoder_norm_train = normalize_scores(autoencoder_anomaly_scores_train)\n",
    "autoencoder_norm_test = normalize_scores(autoencoder_anomaly_scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Individual Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate ROC AUC for a model\n",
    "def calculate_roc_auc(y_true, scores):\n",
    "    fpr, tpr, _ = roc_curve(y_true, scores)\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "# Function to calculate PR AUC for a model\n",
    "def calculate_pr_auc(y_true, scores):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, scores)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "# Calculate AUC for each model\n",
    "iso_forest_roc_auc = calculate_roc_auc(y_test, iso_forest_norm_test)\n",
    "lof_roc_auc = calculate_roc_auc(y_test, lof_norm_test)\n",
    "ocsvm_roc_auc = calculate_roc_auc(y_test, ocsvm_norm_test)\n",
    "mahal_roc_auc = calculate_roc_auc(y_test, mahal_norm_test)\n",
    "autoencoder_roc_auc = calculate_roc_auc(y_test, autoencoder_norm_test)\n",
    "\n",
    "iso_forest_pr_auc = calculate_pr_auc(y_test, iso_forest_norm_test)\n",
    "lof_pr_auc = calculate_pr_auc(y_test, lof_norm_test)\n",
    "ocsvm_pr_auc = calculate_pr_auc(y_test, ocsvm_norm_test)\n",
    "mahal_pr_auc = calculate_pr_auc(y_test, mahal_norm_test)\n",
    "autoencoder_pr_auc = calculate_pr_auc(y_test, autoencoder_norm_test)\n",
    "\n",
    "# Print results\n",
    "print(\"ROC AUC Scores:\")\n",
    "print(f\"Isolation Forest: {iso_forest_roc_auc:.4f}\")\n",
    "print(f\"Local Outlier Factor: {lof_roc_auc:.4f}\")\n",
    "print(f\"One-Class SVM: {ocsvm_roc_auc:.4f}\")\n",
    "print(f\"PCA-Mahalanobis: {mahal_roc_auc:.4f}\")\n",
    "print(f\"Autoencoder: {autoencoder_roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nPR AUC Scores:\")\n",
    "print(f\"Isolation Forest: {iso_forest_pr_auc:.4f}\")\n",
    "print(f\"Local Outlier Factor: {lof_pr_auc:.4f}\")\n",
    "print(f\"One-Class SVM: {ocsvm_pr_auc:.4f}\")\n",
    "print(f\"PCA-Mahalanobis: {mahal_pr_auc:.4f}\")\n",
    "print(f\"Autoencoder: {autoencoder_pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for all models\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Isolation Forest\n",
    "fpr, tpr, _ = roc_curve(y_test, iso_forest_norm_test)\n",
    "plt.plot(fpr, tpr, label=f'Isolation Forest (AUC = {iso_forest_roc_auc:.4f})')\n",
    "\n",
    "# Local Outlier Factor\n",
    "fpr, tpr, _ = roc_curve(y_test, lof_norm_test)\n",
    "plt.plot(fpr, tpr, label=f'Local Outlier Factor (AUC = {lof_roc_auc:.4f})')\n",
    "\n",
    "# One-Class SVM\n",
    "fpr, tpr, _ = roc_curve(y_test, ocsvm_norm_test)\n",
    "plt.plot(fpr, tpr, label=f'One-Class SVM (AUC = {ocsvm_roc_auc:.4f})')\n",
    "\n",
    "# PCA-Mahalanobis\n",
    "fpr, tpr, _ = roc_curve(y_test, mahal_norm_test)\n",
    "plt.plot(fpr, tpr, label=f'PCA-Mahalanobis (AUC = {mahal_roc_auc:.4f})')\n",
    "\n",
    "# Autoencoder\n",
    "fpr, tpr, _ = roc_curve(y_test, autoencoder_norm_test)\n",
    "plt.plot(fpr, tpr, label=f'Autoencoder (AUC = {autoencoder_roc_auc:.4f})')\n",
    "\n",
    "# Reference line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Individual Models')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with all normalized scores\n",
    "ensemble_train_df = pd.DataFrame({\n",
    "    'iso_forest': iso_forest_norm_train,\n",
    "    'lof': lof_norm_train,\n",
    "    'ocsvm': ocsvm_norm_train,\n",
    "    'mahalanobis': mahal_norm_train,\n",
    "    'autoencoder': autoencoder_norm_train\n",
    "})\n",
    "\n",
    "ensemble_test_df = pd.DataFrame({\n",
    "    'iso_forest': iso_forest_norm_test,\n",
    "    'lof': lof_norm_test,\n",
    "    'ocsvm': ocsvm_norm_test,\n",
    "    'mahalanobis': mahal_norm_test,\n",
    "    'autoencoder': autoencoder_norm_test\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Simple Averaging Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average scores\n",
    "ensemble_avg_train = ensemble_train_df.mean(axis=1)\n",
    "ensemble_avg_test = ensemble_test_df.mean(axis=1)\n",
    "\n",
    "# Calculate ROC AUC and PR AUC for average ensemble\n",
    "ensemble_avg_roc_auc = calculate_roc_auc(y_test, ensemble_avg_test)\n",
    "ensemble_avg_pr_auc = calculate_pr_auc(y_test, ensemble_avg_test)\n",
    "\n",
    "print(f\"Average Ensemble ROC AUC: {ensemble_avg_roc_auc:.4f}\")\n",
    "print(f\"Average Ensemble PR AUC: {ensemble_avg_pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Weighted Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights based on individual model performance (ROC AUC)\n",
    "weights = {\n",
    "    'iso_forest': iso_forest_roc_auc,\n",
    "    'lof': lof_roc_auc,\n",
    "    'ocsvm': ocsvm_roc_auc,\n",
    "    'mahalanobis': mahal_roc_auc,\n",
    "    'autoencoder': autoencoder_roc_auc\n",
    "}\n",
    "\n",
    "# Normalize weights to sum to 1\n",
    "total_weight = sum(weights.values())\n",
    "normalized_weights = {k: v/total_weight for k, v in weights.items()}\n",
    "\n",
    "print(\"Normalized weights:\")\n",
    "for model, weight in normalized_weights.items():\n",
    "    print(f\"{model}: {weight:.4f}\")\n",
    "\n",
    "# Calculate weighted scores\n",
    "ensemble_weighted_train = sum(ensemble_train_df[model] * weight for model, weight in normalized_weights.items())\n",
    "ensemble_weighted_test = sum(ensemble_test_df[model] * weight for model, weight in normalized_weights.items())\n",
    "\n",
    "# Calculate ROC AUC and PR AUC for weighted ensemble\n",
    "ensemble_weighted_roc_auc = calculate_roc_auc(y_test, ensemble_weighted_test)\n",
    "ensemble_weighted_pr_auc = calculate_pr_auc(y_test, ensemble_weighted_test)\n",
    "\n",
    "print(f\"\\nWeighted Ensemble ROC AUC: {ensemble_weighted_roc_auc:.4f}\")\n",
    "print(f\"Weighted Ensemble PR AUC: {ensemble_weighted_pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Maximum Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate maximum scores (taking the most anomalous score for each sample)\n",
    "ensemble_max_train = ensemble_train_df.max(axis=1)\n",
    "ensemble_max_test = ensemble_test_df.max(axis=1)\n",
    "\n",
    "# Calculate ROC AUC and PR AUC for maximum ensemble\n",
    "ensemble_max_roc_auc = calculate_roc_auc(y_test, ensemble_max_test)\n",
    "ensemble_max_pr_auc = calculate_pr_auc(y_test, ensemble_max_test)\n",
    "\n",
    "print(f\"Maximum Ensemble ROC AUC: {ensemble_max_roc_auc:.4f}\")\n",
    "print(f\"Maximum Ensemble PR AUC: {ensemble_max_pr_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for all ensemble methods\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Average Ensemble\n",
    "fpr, tpr, _ = roc_curve(y_test, ensemble_avg_test)\n",
    "plt.plot(fpr, tpr, label=f'Average Ensemble (AUC = {ensemble_avg_roc_auc:.4f})')\n",
    "\n",
    "# Weighted Ensemble\n",
    "fpr, tpr, _ = roc_curve(y_test, ensemble_weighted_test)\n",
    "plt.plot(fpr, tpr, label=f'Weighted Ensemble (AUC = {ensemble_weighted_roc_auc:.4f})')\n",
    "\n",
    "# Maximum Ensemble\n",
    "fpr, tpr, _ = roc_curve(y_test, ensemble_max_test)\n",
    "plt.plot(fpr, tpr, label=f'Maximum Ensemble (AUC = {ensemble_max_roc_auc:.4f})')\n",
    "\n",
    "# Best Individual Model\n",
    "best_model = max([\n",
    "    ('Isolation Forest', iso_forest_roc_auc, iso_forest_norm_test),\n",
    "    ('Local Outlier Factor', lof_roc_auc, lof_norm_test),\n",
    "    ('One-Class SVM', ocsvm_roc_auc, ocsvm_norm_test),\n",
    "    ('PCA-Mahalanobis', mahal_roc_auc, mahal_norm_test),\n",
    "    ('Autoencoder', autoencoder_roc_auc, autoencoder_norm_test)\n",
    "], key=lambda x: x[1])\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, best_model[2])\n",
    "plt.plot(fpr, tpr, label=f'Best Individual: {best_model[0]} (AUC = {best_model[1]:.4f})')\n",
    "\n",
    "# Reference line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Ensemble Methods')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the best ensemble method\n",
    "ensemble_methods = [\n",
    "    ('Average Ensemble', ensemble_avg_roc_auc, ensemble_avg_test),\n",
    "    ('Weighted Ensemble', ensemble_weighted_roc_auc, ensemble_weighted_test),\n",
    "    ('Maximum Ensemble', ensemble_max_roc_auc, ensemble_max_test)\n",
    "]\n",
    "\n",
    "best_ensemble = max(ensemble_methods, key=lambda x: x[1])\n",
    "print(f\"Best ensemble method: {best_ensemble[0]} with ROC AUC = {best_ensemble[1]:.4f}\")\n",
    "\n",
    "# Use the best ensemble method for further analysis\n",
    "best_ensemble_scores = best_ensemble[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Threshold Optimization for Best Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different thresholds for anomaly detection\n",
    "thresholds = np.linspace(min(best_ensemble_scores), max(best_ensemble_scores), 100)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = np.where(best_ensemble_scores >= threshold, 1, 0)\n",
    "    f1_scores.append(f1_score(y_test, y_pred_threshold))\n",
    "    precision_scores.append(precision_score(y_test, y_pred_threshold))\n",
    "    recall_scores.append(recall_score(y_test, y_pred_threshold))\n",
    "\n",
    "# Find the threshold that maximizes F1 score\n",
    "best_threshold_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_idx]\n",
    "best_f1 = f1_scores[best_threshold_idx]\n",
    "best_precision = precision_scores[best_threshold_idx]\n",
    "best_recall = recall_scores[best_threshold_idx]\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.4f}\")\n",
    "print(f\"Best F1 score: {best_f1:.4f}\")\n",
    "print(f\"Precision at best threshold: {best_precision:.4f}\")\n",
    "print(f\"Recall at best threshold: {best_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot F1, precision, and recall scores for different thresholds\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(thresholds, f1_scores, 'b-', label='F1 Score')\n",
    "plt.plot(thresholds, precision_scores, 'g-', label='Precision')\n",
    "plt.plot(thresholds, recall_scores, 'r-', label='Recall')\n",
    "plt.axvline(x=best_threshold, color='k', linestyle='--', label=f'Best Threshold: {best_threshold:.4f}')\n",
    "plt.title('Performance Metrics vs. Threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the optimized threshold\n",
    "y_pred_optimized = np.where(best_ensemble_scores >= best_threshold, 1, 0)\n",
    "\n",
    "# Evaluate with optimized threshold\n",
    "print(\"Confusion Matrix with Optimized Threshold:\")\n",
    "cm_optimized = confusion_matrix(y_test, y_pred_optimized)\n",
    "print(cm_optimized)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_optimized, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Normal', 'Anomaly'],\n",
    "            yticklabels=['Normal', 'Anomaly'])\n",
    "plt.title('Confusion Matrix with Optimized Threshold')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report with Optimized Threshold:\")\n",
    "print(classification_report(y_test, y_pred_optimized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Analyze Anomalies Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with timestamps, actual labels, and predictions\n",
    "results_df = pd.DataFrame({\n",
    "    'timestamp': test_df['timestamp'],\n",
    "    'actual': y_test,\n",
    "    'predicted': y_pred_optimized,\n",
    "    'anomaly_score': best_ensemble_scores\n",
    "})\n",
    "\n",
    "# Plot actual vs predicted anomalies over time\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Sample data for better visualization if dataset is large\n",
    "sample_size = min(10000, len(results_df))\n",
    "sample_indices = np.linspace(0, len(results_df)-1, sample_size, dtype=int)\n",
    "sample_df = results_df.iloc[sample_indices]\n",
    "\n",
    "plt.plot(sample_df['timestamp'], sample_df['actual'], 'b-', alpha=0.5, label='Actual')\n",
    "plt.plot(sample_df['timestamp'], sample_df['predicted'], 'r-', alpha=0.5, label='Predicted')\n",
    "plt.title('Actual vs Predicted Anomalies Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly (1) / Normal (0)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot anomaly scores over time with actual labels\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Create a colormap based on actual labels\n",
    "colors = np.where(sample_df['actual'] == 1, 'red', 'blue')\n",
    "\n",
    "plt.scatter(sample_df['timestamp'], sample_df['anomaly_score'], c=colors, alpha=0.5, s=10)\n",
    "plt.title('Anomaly Scores Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a horizontal line at the threshold\n",
    "plt.axhline(y=best_threshold, color='g', linestyle='--')\n",
    "\n",
    "# Add a legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Actual Anomaly'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Normal'),\n",
    "    Line2D([0], [0], color='g', linestyle='--', label='Threshold')\n",
    "]\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save the Models and Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save the models if it doesn't exist\n",
    "model_dir = \"./\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save individual models\n",
    "with open(os.path.join(model_dir, \"isolation_forest_model.pkl\"), 'wb') as file:\n",
    "    pickle.dump(iso_forest, file)\n",
    "    \n",
    "with open(os.path.join(model_dir, \"lof_model.pkl\"), 'wb') as file:\n",
    "    pickle.dump(lof, file)\n",
    "    \n",
    "with open(os.path.join(model_dir, \"ocsvm_model.pkl\"), 'wb') as file:\n",
    "    pickle.dump(ocsvm, file)\n",
    "    \n",
    "with open(os.path.join(model_dir, \"pca_model.pkl\"), 'wb') as file:\n",
    "    pickle.dump(pca, file)\n",
    "    \n",
    "with open(os.path.join(model_dir, \"covariance_model.pkl\"), 'wb') as file:\n",
    "    pickle.dump(cov, file)\n",
    "    \n",
    "with open(os.path.join(model_dir, \"mean_vector.pkl\"), 'wb') as file:\n",
    "    pickle.dump(mean_vec, file)\n",
    "    \n",
    "# Save autoencoder model\n",
    "autoencoder.save(os.path.join(model_dir, \"autoencoder_model.h5\"))\n",
    "\n",
    "# Save scaler\n",
    "with open(os.path.join(model_dir, \"scaler.pkl\"), 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "    \n",
    "# Save ensemble information\n",
    "ensemble_info = {\n",
    "    'best_ensemble_method': best_ensemble[0],\n",
    "    'best_threshold': best_threshold,\n",
    "    'normalized_weights': normalized_weights if best_ensemble[0] == 'Weighted Ensemble' else None\n",
    "}\n",
    "\n",
    "with open(os.path.join(model_dir, \"ensemble_info.pkl\"), 'wb') as file:\n",
    "    pickle.dump(ensemble_info, file)\n",
    "    \n",
    "print(\"All models and ensemble information saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we have:\n",
    "\n",
    "1. Loaded and preprocessed the HAI-23.05 dataset\n",
    "2. Implemented five different anomaly detection models:\n",
    "   - Isolation Forest\n",
    "   - Local Outlier Factor\n",
    "   - One-Class SVM\n",
    "   - PCA with Mahalanobis Distance\n",
    "   - Autoencoder\n",
    "3. Evaluated each model's performance using ROC AUC and PR AUC\n",
    "4. Created three ensemble methods:\n",
    "   - Simple Averaging\n",
    "   - Weighted Ensemble\n",
    "   - Maximum Ensemble\n",
    "5. Identified the best ensemble method and optimized its threshold\n",
    "6. Analyzed anomaly detection results over time\n",
    "7. Saved all models and ensemble information for future use\n",
    "\n",
    "The ensemble approach has demonstrated superior performance compared to individual models, leveraging the strengths of different anomaly detection techniques. This approach is particularly effective for industrial control systems where different types of anomalies may be better detected by different methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}