{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI 20.07 Dataset: Optimized Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to improve the visualization performance compared to `1_data_exploration.ipynb` by:\n",
    "1. Using more aggressive data sampling.\n",
    "2. Using Plotly's `Scattergl` traces, which are optimized for larger datasets via WebGL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Set Plotly default theme\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset\n",
    "data_dir = \"../../hai-security-dataset/hai-20.07/\"\n",
    "train_file = os.path.join(data_dir, \"train1.csv\")\n",
    "\n",
    "print(f\"Train file path: {train_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data using Polars\n",
    "df_train = None\n",
    "try:\n",
    "    df_train = pl.read_csv(\n",
    "        train_file,\n",
    "        separator=';',\n",
    "        try_parse_dates=False,\n",
    "        infer_schema_length=10000\n",
    "    )\n",
    "    df_train = df_train.with_columns(\n",
    "        pl.col('time').str.strptime(pl.Datetime, format=\"%Y-%m-%d %H:%M:%S\").alias('time')\n",
    "    ).sort('time')\n",
    "    print(\"Training data loaded successfully.\")\n",
    "    print(f\"Shape: {df_train.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading training data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimized Feature Visualization (Grouped Scattergl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensor_group_optimized(df, features, title_suffix=\"\", sample_frac=50, max_points_marker=5000):\n",
    "    \"\"\"Helper function to plot a group of sensors using Scattergl and more sampling.\"\"\"\n",
    "    if df is None or not features:\n",
    "        print(f\"Skipping plot for group {title_suffix}: Data not loaded or no features.\")\n",
    "        return\n",
    "        \n",
    "    plot_cols = ['time', 'attack'] + [col for col in features if col in df.columns]\n",
    "    if len(plot_cols) <= 2:\n",
    "        print(f\"Skipping plot for group {title_suffix}: Could not find specified features in DataFrame.\")\n",
    "        return\n",
    "        \n",
    "    # --- More Aggressive Sampling --- \n",
    "    rows_before_sampling = df.height\n",
    "    if rows_before_sampling > 20000: # Start sampling earlier\n",
    "         print(f\"Sampling data (1/{sample_frac}) for plotting group {title_suffix} ({rows_before_sampling} rows).\")\n",
    "         slice_len = (rows_before_sampling // sample_frac) * sample_frac\n",
    "         # Use pl.len() instead of pl.count()\n",
    "         df_sample = df.select(plot_cols).slice(0, slice_len).filter(pl.int_range(0, pl.len()).mod(sample_frac) == 0)\n",
    "         plot_title = f'Sensor Readings (Group {title_suffix}) - Sampled 1/{sample_frac}'\n",
    "    else:\n",
    "         df_sample = df.select(plot_cols)\n",
    "         plot_title = f'Sensor Readings (Group {title_suffix})'\n",
    "    # --- End Sampling Logic ---\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    try:\n",
    "        # Add Scattergl traces for sensors\n",
    "        df_sample_pd = df_sample.to_pandas() # Convert once for plotting\n",
    "        for sensor in features:\n",
    "            if sensor in df_sample_pd.columns:\n",
    "                fig.add_trace(\n",
    "                    go.Scattergl(x=df_sample_pd['time'], y=df_sample_pd[sensor], mode='lines', name=sensor)\n",
    "                )\n",
    "        \n",
    "        # Add attack markers using Scattergl\n",
    "        attack_points = df_sample.filter(pl.col('attack') == 1)\n",
    "        if attack_points.height > 0 and attack_points.height < max_points_marker:\n",
    "             # print(f\"Adding {attack_points.height} attack markers for group {title_suffix}...\") # Optional\n",
    "             attack_points_pd = attack_points.to_pandas()\n",
    "             # Use first available sensor in the group for y-axis reference if possible\n",
    "             y_marker_ref_col = next((f for f in features if f in attack_points_pd.columns), None)\n",
    "             if y_marker_ref_col:\n",
    "                 fig.add_trace(go.Scattergl(x=attack_points_pd['time'], \n",
    "                                          y=attack_points_pd[y_marker_ref_col], \n",
    "                                          mode='markers', name='Attack', \n",
    "                                          marker=dict(color='red', size=6, symbol='x', opacity=0.7)))\n",
    "        elif attack_points.height >= max_points_marker:\n",
    "             print(f\"Too many attack points ({attack_points.height}) for group {title_suffix}, skipping markers.\")\n",
    "\n",
    "        fig.update_layout(title=plot_title, xaxis_title=\"Time\", yaxis_title=\"Value\", height=400)\n",
    "        fig.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during plotting group {title_suffix}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical sensor columns for plotting\n",
    "if df_train is not None:\n",
    "    exclude_cols = ['time', 'attack', 'attack_P1', 'attack_P2', 'attack_P3']\n",
    "    sensor_cols = [\n",
    "        col for col, dtype in df_train.schema.items() \n",
    "        if dtype in pl.NUMERIC_DTYPES and col not in exclude_cols\n",
    "    ]\n",
    "    print(f\"Found {len(sensor_cols)} numerical sensor columns to plot.\")\n",
    "\n",
    "    # Plot in groups using the optimized function\n",
    "    group_size = 8\n",
    "    num_groups = math.ceil(len(sensor_cols) / group_size)\n",
    "\n",
    "    for i in range(num_groups):\n",
    "        start_idx = i * group_size\n",
    "        end_idx = start_idx + group_size\n",
    "        feature_group = sensor_cols[start_idx:end_idx]\n",
    "        # Use the new optimized plotting function\n",
    "        plot_sensor_group_optimized(df_train, feature_group, title_suffix=f\"{i+1}/{num_groups}\", sample_frac=50)\n",
    "else:\n",
    "    print(\"Data not loaded, cannot plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Further Exploration Ideas\n",
    "\n",
    "*   **Correlation Analysis:** Examine correlations between different sensors.\n",
    "*   **Distribution Plots:** Use histograms or density plots for individual features.\n",
    "*   **Time-based Aggregations:** Analyze sensor behavior aggregated over minutes, hours, etc.\n",
    "*   **Load Test Data:** Perform similar initial analysis on the test datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
