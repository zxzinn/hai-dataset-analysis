{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Deep Learning Models for HAI Security Dataset Anomaly Detection\n",
    "\n",
    "This notebook implements advanced deep learning architectures for anomaly detection on the HAI security dataset. We'll explore CNN-LSTM hybrid models and Transformer-based approaches, which can capture both spatial and temporal patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, TimeDistributed, Flatten, RepeatVector, Attention\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Check for GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    print(\"GPU is available for training\")\n",
    "    # Set memory growth to avoid memory allocation errors\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"No GPU available, using CPU for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data\n",
    "\n",
    "First, let's load the preprocessed data created in the preprocessing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_processed_data(file_path):\n",
    "    \"\"\"\n",
    "    Load processed data from NPZ file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the NPZ file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Loaded data\n",
    "    \"\"\"\n",
    "    # Load NPZ file\n",
    "    npz_data = np.load(file_path, allow_pickle=True)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(npz_data['data'], columns=npz_data['columns'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load preprocessor\n",
    "preprocessor_path = './models/hai_hai_20_07_standard_preprocessor.joblib'\n",
    "preprocessor_dict = joblib.load(preprocessor_path)\n",
    "\n",
    "# Extract important information\n",
    "feature_columns = preprocessor_dict['feature_columns']\n",
    "attack_columns = preprocessor_dict['attack_columns']\n",
    "timestamp_col = preprocessor_dict['timestamp_col']\n",
    "\n",
    "print(f\"Number of features: {len(feature_columns)}\")\n",
    "print(f\"Attack columns: {attack_columns}\")\n",
    "print(f\"Timestamp column: {timestamp_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get list of processed data files\n",
    "train_data_dir = './processed_data/hai-20.07/train'\n",
    "test_data_dir = './processed_data/hai-20.07/test'\n",
    "\n",
    "train_files = sorted(glob.glob(f'{train_data_dir}/*.npz'))\n",
    "test_files = sorted(glob.glob(f'{test_data_dir}/*.npz'))\n",
    "\n",
    "print(f\"Training files: {[os.path.basename(f) for f in train_files]}\")\n",
    "print(f\"Test files: {[os.path.basename(f) for f in test_files]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for Advanced Models\n",
    "\n",
    "We'll prepare sequence data for our advanced deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_sequences(data, feature_cols, target_col=None, seq_length=100):\n",
    "    \"\"\"\n",
    "    Create sequences for deep learning models.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame containing the data\n",
    "        feature_cols: List of feature column names\n",
    "        target_col: Target column name (None for unsupervised learning)\n",
    "        seq_length: Length of each sequence\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (X, y) - Sequences and targets (if target_col is provided)\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = [] if target_col is not None else None\n",
    "    \n",
    "    # Extract features\n",
    "    features = data[feature_cols].values\n",
    "    \n",
    "    # Extract target if provided\n",
    "    targets = data[target_col].values if target_col is not None else None\n",
    "    \n",
    "    # Create sequences\n",
    "    for i in range(len(features) - seq_length):\n",
    "        X.append(features[i:i+seq_length])\n",
    "        if target_col is not None:\n",
    "            # Use the label of the last timestep in the sequence\n",
    "            y.append(targets[i+seq_length])\n",
    "    \n",
    "    return np.array(X), np.array(y) if target_col is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_and_prepare_sequence_data(file_paths, feature_cols, target_col=None, seq_length=100, max_files=None):\n",
    "    \"\"\"\n",
    "    Load and prepare sequence data from multiple files.\n",
    "    \n",
    "    Args:\n",
    "        file_paths: List of file paths\n",
    "        feature_cols: List of feature column names\n",
    "        target_col: Target column name (None for unsupervised learning)\n",
    "        seq_length: Length of each sequence\n",
    "        max_files: Maximum number of files to load (None for all files)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (X, y) - Combined sequences and targets\n",
    "    \"\"\"\n",
    "    all_X = []\n",
    "    all_y = [] if target_col is not None else None\n",
    "    \n",
    "    # Limit the number of files if specified\n",
    "    if max_files is not None:\n",
    "        file_paths = file_paths[:max_files]\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        print(f\"Processing {os.path.basename(file_path)}...\")\n",
    "        \n",
    "        # Load data\n",
    "        df = load_processed_data(file_path)\n",
    "        \n",
    "        # Create sequences\n",
    "        X, y = create_sequences(df, feature_cols, target_col, seq_length)\n",
    "        \n",
    "        all_X.append(X)\n",
    "        if target_col is not None:\n",
    "            all_y.append(y)\n",
    "    \n",
    "    # Combine data from all files\n",
    "    combined_X = np.vstack(all_X) if all_X else np.array([])\n",
    "    combined_y = np.concatenate(all_y) if all_y else None\n",
    "    \n",
    "    return combined_X, combined_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set parameters\n",
    "target_col = 'attack' if attack_columns else None  # Target column\n",
    "seq_length = 100  # Sequence length\n",
    "\n",
    "# Load and prepare training data\n",
    "print(\"Loading and preparing training data...\")\n",
    "X_train, _ = load_and_prepare_sequence_data(train_files, feature_columns, target_col=None, \n",
    "                                           seq_length=seq_length, max_files=2)\n",
    "\n",
    "# Load and prepare test data\n",
    "print(\"\\nLoading and preparing test data...\")\n",
    "X_test, y_test = load_and_prepare_sequence_data(test_files, feature_columns, target_col=target_col, \n",
    "                                               seq_length=seq_length, max_files=2)\n",
    "\n",
    "print(f\"\\nTraining data shape: {X_train.shape}\")\n",
    "if y_test is not None:\n",
    "    print(f\"Test data shape: {X_test.shape}, Test labels shape: {y_test.shape}\")\n",
    "else:\n",
    "    print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert data to float32 for neural network models\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN-LSTM Hybrid Model\n",
    "\n",
    "First, let's implement a CNN-LSTM hybrid model that combines convolutional layers for feature extraction with LSTM layers for temporal modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def build_cnn_lstm_autoencoder(input_shape, encoding_dim=32, filters=[64, 128], kernel_size=3, lstm_units=[64, 32]):\n",
    "    \"\"\"\n",
    "    Build a CNN-LSTM autoencoder model.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input data (seq_length, num_features)\n",
    "        encoding_dim: Dimension of the encoded representation\n",
    "        filters: List of filter sizes for CNN layers\n",
    "        kernel_size: Kernel size for CNN layers\n",
    "        lstm_units: List of units for LSTM layers\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (model, encoder, decoder) - Full model, encoder part, and decoder part\n",
    "    \"\"\"\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    \n",
    "    # CNN layers for feature extraction\n",
    "    x = encoder_inputs\n",
    "    for i, filter_size in enumerate(filters):\n",
    "        x = Conv1D(filters=filter_size, kernel_size=kernel_size, activation='relu', padding='same', name=f'encoder_conv_{i+1}')(x)\n",
    "        x = BatchNormalization(name=f'encoder_bn_conv_{i+1}')(x)\n",
    "        x = MaxPooling1D(pool_size=2, padding='same', name=f'encoder_pool_{i+1}')(x)\n",
    "    \n",
    "    # LSTM layers for temporal modeling\n",
    "    for i, units in enumerate(lstm_units[:-1]):\n",
    "        x = Bidirectional(LSTM(units, return_sequences=True, name=f'encoder_lstm_{i+1}'))(x)\n",
    "        x = BatchNormalization(name=f'encoder_bn_lstm_{i+1}')(x)\n",
    "    \n",
    "    # Final LSTM layer\n",
    "    x = Bidirectional(LSTM(lstm_units[-1], return_sequences=False, name=f'encoder_lstm_{len(lstm_units)}'))(x)\n",
    "    x = BatchNormalization(name=f'encoder_bn_lstm_{len(lstm_units)}')(x)\n",
    "    \n",
    "    # Bottleneck layer\n",
    "    encoder_output = Dense(encoding_dim, activation='relu', name='encoder_output')(x)\n",
    "    \n",
    "    # Create encoder model\n",
    "    encoder = Model(encoder_inputs, encoder_output, name='encoder')\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(encoding_dim,), name='decoder_input')\n",
    "    \n",
    "    # Dense layer to match LSTM input dimensions\n",
    "    x = Dense(lstm_units[-1] * 2, activation='relu', name='decoder_dense_1')(decoder_inputs)  # *2 for bidirectional\n",
    "    x = BatchNormalization(name='decoder_bn_dense_1')(x)\n",
    "    \n",
    "    # Calculate sequence length after pooling operations\n",
    "    pooled_seq_length = input_shape[0] // (2 ** len(filters))\n",
    "    \n",
    "    # Repeat vector to create sequence\n",
    "    x = RepeatVector(pooled_seq_length, name='decoder_repeat')(x)\n",
    "    \n",
    "    # LSTM layers\n",
    "    for i, units in enumerate(reversed(lstm_units)):\n",
    "        x = Bidirectional(LSTM(units, return_sequences=True, name=f'decoder_lstm_{i+1}'))(x)\n",
    "        x = BatchNormalization(name=f'decoder_bn_lstm_{i+1}')(x)\n",
    "    \n",
    "    # Upsampling to original sequence length using Conv1D and UpSampling1D\n",
    "    for i, filter_size in enumerate(reversed(filters)):\n",
    "        # Upsampling\n",
    "        x = TimeDistributed(Dense(filter_size * 2, activation='relu'), name=f'decoder_upsample_{i+1}')(x)\n",
    "        # Reshape to double the sequence length\n",
    "        current_shape = x.shape\n",
    "        target_shape = (current_shape[1] * 2, filter_size)\n",
    "        x = Reshape(target_shape, name=f'decoder_reshape_{i+1}')(x)\n",
    "        \n",
    "        # Conv1D for smoothing\n",
    "        x = Conv1D(filters=filter_size, kernel_size=kernel_size, activation='relu', padding='same', name=f'decoder_conv_{i+1}')(x)\n",
    "        x = BatchNormalization(name=f'decoder_bn_conv_{i+1}')(x)\n",
    "    \n",
    "    # Output layer\n",
    "    decoder_output = Conv1D(filters=input_shape[1], kernel_size=1, activation='linear', padding='same', name='decoder_output')(x)\n",
    "    \n",
    "    # Create decoder model\n",
    "    decoder = Model(decoder_inputs, decoder_output, name='decoder')\n",
    "    \n",
    "    # Create autoencoder model\n",
    "    autoencoder_input = Input(shape=input_shape, name='autoencoder_input')\n",
    "    encoded = encoder(autoencoder_input)\n",
    "    decoded = decoder(encoded)\n",
    "    autoencoder = Model(autoencoder_input, decoded, name='cnn_lstm_autoencoder')\n",
    "    \n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set model parameters\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # (seq_length, num_features)\n",
    "encoding_dim = 32  # Dimension of the encoded representation\n",
    "filters = [32, 64]  # Filter sizes for CNN layers\n",
    "kernel_size = 3  # Kernel size for CNN layers\n",
    "lstm_units = [64, 32]  # Units for LSTM layers\n",
    "\n",
    "# Build model\n",
    "cnn_lstm_autoencoder, cnn_lstm_encoder, cnn_lstm_decoder = build_cnn_lstm_autoencoder(\n",
    "    input_shape, encoding_dim, filters, kernel_size, lstm_units\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "cnn_lstm_autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Print model summary\n",
    "cnn_lstm_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train CNN-LSTM Model\n",
    "\n",
    "Now we'll train the CNN-LSTM model on normal data to learn the normal behavior patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set training parameters\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "validation_split = 0.1\n",
    "\n",
    "# Create model checkpoint callback\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "checkpoint_path = './models/cnn_lstm_autoencoder_hai_20_07.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')\n",
    "\n",
    "# Create early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience=10, \n",
    "                              verbose=1, \n",
    "                              mode='min', \n",
    "                              restore_best_weights=True)\n",
    "\n",
    "# Create learning rate scheduler callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                             factor=0.5, \n",
    "                             patience=5, \n",
    "                             verbose=1, \n",
    "                             min_lr=0.0001)\n",
    "\n",
    "# Create TensorBoard callback\n",
    "log_dir = './logs/cnn_lstm_autoencoder_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = TensorBoard(log_dir=log_dir, \n",
    "                         histogram_freq=1, \n",
    "                         write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "# Combine callbacks\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "\n",
    "cnn_lstm_history = cnn_lstm_autoencoder.fit(\n",
    "    X_train, X_train,  # Input and output are the same for autoencoder\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=validation_split,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(cnn_lstm_history.history['loss'])\n",
    "plt.plot(cnn_lstm_history.history['val_loss'])\n",
    "plt.title('CNN-LSTM Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "# Plot zoomed-in view of the last epochs\n",
    "plt.subplot(1, 2, 2)\n",
    "last_epochs = min(20, len(cnn_lstm_history.history['loss']))  # Last 20 epochs or all if less\n",
    "plt.plot(cnn_lstm_history.history['loss'][-last_epochs:])\n",
    "plt.plot(cnn_lstm_history.history['val_loss'][-last_epochs:])\n",
    "plt.title(f'CNN-LSTM Model Loss (Last {last_epochs} Epochs)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transformer-Based Model\n",
    "\n",
    "Now let's implement a Transformer-based model for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def transformer_encoder_block(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    \"\"\"\n",
    "    Transformer encoder block.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Input tensor\n",
    "        head_size: Size of each attention head\n",
    "        num_heads: Number of attention heads\n",
    "        ff_dim: Hidden layer size in feed forward network\n",
    "        dropout: Dropout rate\n",
    "        \n",
    "    Returns:\n",
    "        tensor: Output tensor\n",
    "    \"\"\"\n",
    "    # Multi-head attention\n",
    "    attention_output = MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    \n",
    "    # Add & Normalize (first residual connection)\n",
    "    attention_output = LayerNormalization(epsilon=1e-6)(inputs + attention_output)\n",
    "    \n",
    "    # Feed Forward Network\n",
    "    ffn_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n",
    "    ffn_output = Dense(inputs.shape[-1])(ffn_output)\n",
    "    \n",
    "    # Add & Normalize (second residual connection)\n",
    "    return LayerNormalization(epsilon=1e-6)(attention_output + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def build_transformer_autoencoder(input_shape, head_size=64, num_heads=4, ff_dim=256, num_transformer_blocks=2, encoding_dim=32):\n",
    "    \"\"\"\n",
    "    Build a Transformer-based autoencoder model.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input data (seq_length, num_features)\n",
    "        head_size: Size of each attention head\n",
    "        num_heads: Number of attention heads\n",
    "        ff_dim: Hidden layer size in feed forward network\n",
    "        num_transformer_blocks: Number of transformer blocks\n",
    "        encoding_dim: Dimension of the encoded representation\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (model, encoder, decoder) - Full model, encoder part, and decoder part\n",
    "    \"\"\"\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    \n",
    "    # Initial projection\n",
    "    x = Conv1D(filters=ff_dim, kernel_size=1, activation='relu', padding='same')(encoder_inputs)\n",
    "    \n",
    "    # Transformer blocks\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder_block(x, head_size, num_heads, ff_dim)\n",
    "    \n",
    "    # Global pooling\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Bottleneck layer\n",
    "    encoder_output = Dense(encoding_dim, activation='relu', name='encoder_output')(x)\n",
    "    \n",
    "    # Create encoder model\n",
    "    encoder = Model(encoder_inputs, encoder_output, name='encoder')\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(encoding_dim,), name='decoder_input')\n",
    "    \n",
    "    # Dense layer to match sequence dimensions\n",
    "    x = Dense(ff_dim, activation='relu')(decoder_inputs)\n",
    "    \n",
    "    # Repeat vector to create sequence\n",
    "    x = RepeatVector(input_shape[0])(x)\n",
    "    \n",
    "    # Transformer blocks\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder_block(x, head_size, num_heads, ff_dim)\n",
    "    \n",
    "    # Output layer\n",
    "    decoder_output = TimeDistributed(Dense(input_shape[1]))(x)\n",
    "    \n",
    "    # Create decoder model\n",
    "    decoder = Model(decoder_inputs, decoder_output, name='decoder')\n",
    "    \n",
    "    # Create autoencoder model\n",
    "    autoencoder_input = Input(shape=input_shape, name='autoencoder_input')\n",
    "    encoded = encoder(autoencoder_input)\n",
    "    decoded = decoder(encoded)\n",
    "    autoencoder = Model(autoencoder_input, decoded, name='transformer_autoencoder')\n",
    "    \n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set model parameters\n",
    "head_size = 64  # Size of each attention head\n",
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 256  # Hidden layer size in feed forward network\n",
    "num_transformer_blocks = 2  # Number of transformer blocks\n",
    "encoding_dim = 32  # Dimension of the encoded representation\n",
    "\n",
    "# Build model\n",
    "transformer_autoencoder, transformer_encoder, transformer_decoder = build_transformer_autoencoder(\n",
    "    input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, encoding_dim\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "transformer_autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Print model summary\n",
    "transformer_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Transformer Model\n",
    "\n",
    "Now we'll train the Transformer model on normal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set training parameters\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "validation_split = 0.1\n",
    "\n",
    "# Create model checkpoint callback\n",
    "checkpoint_path = './models/transformer_autoencoder_hai_20_07.h5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')\n",
    "\n",
    "# Create early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience=10, \n",
    "                              verbose=1, \n",
    "                              mode='min', \n",
    "                              restore_best_weights=True)\n",
    "\n",
    "# Create learning rate scheduler callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                             factor=0.5, \n",
    "                             patience=5, \n",
    "                             verbose=1, \n",
    "                             min_lr=0.0001)\n",
    "\n",
    "# Create TensorBoard callback\n",
    "log_dir = './logs/transformer_autoencoder_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = TensorBoard(log_dir=log_dir, \n",
    "                         histogram_freq=1, \n",
    "                         write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "# Combine callbacks\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train model\n",
    "start_time = time.time()\n",
    "\n",
    "transformer_history = transformer_autoencoder.fit(\n",
    "    X_train, X_train,  # Input and output are the same for autoencoder\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=validation_split,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(transformer_history.history['loss'])\n",
    "plt.plot(transformer_history.history['val_loss'])\n",
    "plt.title('Transformer Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "# Plot zoomed-in view of the last epochs\n",
    "plt.subplot(1, 2, 2)\n",
    "last_epochs = min(20, len(transformer_history.history['loss']))  # Last 20 epochs or all if less\n",
    "plt.plot(transformer_history.history['loss'][-last_epochs:])\n",
    "plt.plot(transformer_history.history['val_loss'][-last_epochs:])\n",
    "plt.title(f'Transformer Model Loss (Last {last_epochs} Epochs)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Models and Detect Anomalies\n",
    "\n",
    "Now we'll evaluate both models on the test data and detect anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def find_optimal_threshold(mse, y_true):\n",
    "    \"\"\"\n",
    "    Find the optimal threshold for anomaly detection using ROC curve.\n",
    "    \n",
    "    Args:\n",
    "        mse: Reconstruction error values\n",
    "        y_true: True labels (0 for normal, 1 for anomaly)\n",
    "        \n",
    "    Returns:\n",
    "        float: Optimal threshold value\n",
    "    \"\"\"\n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, mse)\n",
    "    \n",
    "    # Calculate the geometric mean of sensitivity and specificity\n",
    "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
    "    \n",
    "    # Find the optimal threshold\n",
    "    ix = np.argmax(gmeans)\n",
    "    optimal_threshold = thresholds[ix]\n",
    "    \n",
    "    print(f\"Optimal threshold: {optimal_threshold:.6f}\")\n",
    "    print(f\"At this threshold - TPR: {tpr[ix]:.4f}, FPR: {fpr[ix]:.4f}, G-mean: {gmeans[ix]:.4f}\")\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.scatter(fpr[ix], tpr[ix], marker='o', color='red', label=f'Optimal (Threshold = {optimal_threshold:.6f})')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate AUC\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate a model on test data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_test: Test data\n",
    "        y_test: Test labels\n",
    "        model_name: Name of the model\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (mse, threshold, y_pred) - Reconstruction errors, threshold, and predictions\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    # Predict on test data\n",
    "    X_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate reconstruction error (MSE for each sample)\n",
    "    mse = np.mean(np.square(X_test - X_test_pred), axis=(1, 2))\n",
    "    \n",
    "    print(f\"Reconstruction error statistics:\")\n",
    "    print(f\"Min: {np.min(mse):.6f}\")\n",
    "    print(f\"Max: {np.max(mse):.6f}\")\n",
    "    print(f\"Mean: {np.mean(mse):.6f}\")\n",
    "    print(f\"Std: {np.std(mse):.6f}\")\n",
    "    \n",
    "    # Plot reconstruction error distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(mse, bins=50)\n",
    "    plt.title(f'{model_name} Reconstruction Error Distribution')\n",
    "    plt.xlabel('Reconstruction Error (MSE)')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(mse, bins=50, log=True)\n",
    "    plt.title(f'{model_name} Reconstruction Error Distribution (Log Scale)')\n",
    "    plt.xlabel('Reconstruction Error (MSE)')\n",
    "    plt.ylabel('Frequency (Log Scale)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find optimal threshold\n",
    "    threshold = find_optimal_threshold(mse, y_test)\n",
    "    \n",
    "    # Classify as anomaly if reconstruction error > threshold\n",
    "    y_pred = (mse > threshold).astype(int)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"\\n{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return mse, threshold, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the best models\n",
    "best_cnn_lstm_model = load_model('./models/cnn_lstm_autoencoder_hai_20_07.h5')\n",
    "best_transformer_model = load_model('./models/transformer_autoencoder_hai_20_07.h5')\n",
    "\n",
    "# Evaluate CNN-LSTM model\n",
    "cnn_lstm_mse, cnn_lstm_threshold, cnn_lstm_pred = evaluate_model(best_cnn_lstm_model, X_test, y_test, \"CNN-LSTM Model\")\n",
    "\n",
    "# Evaluate Transformer model\n",
    "transformer_mse, transformer_threshold, transformer_pred = evaluate_model(best_transformer_model, X_test, y_test, \"Transformer Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare Model Performance\n",
    "\n",
    "Let's compare the performance of the CNN-LSTM and Transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate metrics for both models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "metrics = {\n",
    "    'CNN-LSTM': {\n",
    "        'accuracy': accuracy_score(y_test, cnn_lstm_pred),\n",
    "        'precision': precision_score(y_test, cnn_lstm_pred),\n",
    "        'recall': recall_score(y_test, cnn_lstm_pred),\n",
    "        'f1': f1_score(y_test, cnn_lstm_pred),\n",
    "        'auc': auc(*roc_curve(y_test, cnn_lstm_mse)[:2])\n",
    "    },\n",
    "    'Transformer': {\n",
    "        'accuracy': accuracy_score(y_test, transformer_pred),\n",
    "        'precision': precision_score(y_test, transformer_pred),\n",
    "        'recall': recall_score(y_test, transformer_pred),\n",
    "        'f1': f1_score(y_test, transformer_pred),\n",
    "        'auc': auc(*roc_curve(y_test, transformer_mse)[:2])\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(metrics).T\n",
    "comparison_df = comparison_df.round(4)\n",
    "\n",
    "# Display comparison\n",
    "print(\"Model Performance Comparison:\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot comparison of key metrics\n",
    "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_data = []\n",
    "for model, model_metrics in metrics.items():\n",
    "    for metric in metrics_to_plot:\n",
    "        plot_data.append({\n",
    "            'Model': model,\n",
    "            'Metric': metric.capitalize(),\n",
    "            'Value': model_metrics[metric]\n",
    "        })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Metric', y='Value', hue='Model', data=plot_df)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylim(0, 1.05)  # Metrics are between 0 and 1\n",
    "plt.grid(axis='y')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Models and Results\n",
    "\n",
    "Let's save the models and results for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save model metadata\n",
    "cnn_lstm_metadata = {\n",
    "    'threshold': cnn_lstm_threshold,\n",
    "    'encoding_dim': encoding_dim,\n",
    "    'filters': filters,\n",
    "    'kernel_size': kernel_size,\n",
    "    'lstm_units': lstm_units,\n",
    "    'feature_columns': feature_columns,\n",
    "    'metrics': metrics['CNN-LSTM'],\n",
    "    'training_history': {\n",
    "        'loss': cnn_lstm_history.history['loss'],\n",
    "        'val_loss': cnn_lstm_history.history['val_loss']\n",
    "    }\n",
    "}\n",
    "\n",
    "transformer_metadata = {\n",
    "    'threshold': transformer_threshold,\n",
    "    'encoding_dim': encoding_dim,\n",
    "    'head_size': head_size,\n",
    "    'num_heads': num_heads,\n",
    "    'ff_dim': ff_dim,\n",
    "    'num_transformer_blocks': num_transformer_blocks,\n",
    "    'feature_columns': feature_columns,\n",
    "    'metrics': metrics['Transformer'],\n",
    "    'training_history': {\n",
    "        'loss': transformer_history.history['loss'],\n",
    "        'val_loss': transformer_history.history['val_loss']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "joblib.dump(cnn_lstm_metadata, './models/cnn_lstm_metadata_hai_20_07.joblib')\n",
    "joblib.dump(transformer_metadata, './models/transformer_metadata_hai_20_07.joblib')\n",
    "\n",
    "print(\"Models and metadata saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this notebook, we've implemented and compared advanced deep learning models for anomaly detection on the HAI security dataset. Key steps included:\n",
    "\n",
    "1. Loading and preparing sequence data\n",
    "2. Building and training a CNN-LSTM hybrid model\n",
    "3. Building and training a Transformer-based model\n",
    "4. Evaluating and comparing model performance\n",
    "5. Saving models and results\n",
    "\n",
    "The advanced deep learning models provide improved anomaly detection performance compared to simpler models, with the ability to capture complex spatial and temporal patterns in the data. The CNN-LSTM hybrid model combines the feature extraction capabilities of CNNs with the temporal modeling of LSTMs, while the Transformer model leverages self-attention mechanisms to capture long-range dependencies in the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}