{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAI 20.07 Dataset: External Plot Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates sensor plots similar to previous versions but saves them as external HTML files instead of embedding them directly. This significantly reduces the notebook file size.\n",
    "\n",
    "Plots will be saved in the `plots/` subdirectory relative to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import math\n",
    "from IPython.display import display, HTML # To display links\n",
    "\n",
    "# Set Plotly default theme\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file path: ../../hai-security-dataset/hai-20.07/train1.csv\n",
      "Output plot directory: plots\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_dir = \"../../../hai-security-dataset/hai-20.07/\"\n",
    "train_file = os.path.join(data_dir, \"train1.csv\")\n",
    "output_plot_dir = \"plots\" # Directory to save HTML plots\n",
    "\n",
    "print(f\"Train file path: {train_file}\")\n",
    "print(f\"Output plot directory: {output_plot_dir}\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_plot_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading training data: No such file or directory (os error 2): ../../hai-security-dataset/hai-20.07/train1.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the training data using Polars\n",
    "df_train = None\n",
    "try:\n",
    "    df_train = pl.read_csv(\n",
    "        train_file,\n",
    "        separator=';',\n",
    "        try_parse_dates=False,\n",
    "        infer_schema_length=100000\n",
    "    )\n",
    "    df_train = df_train.with_columns(\n",
    "        pl.col('time').str.strptime(pl.Datetime, format=\"%Y-%m-%d %H:%M:%S\").alias('time')\n",
    "    ).sort('time')\n",
    "    print(\"Training data loaded successfully.\")\n",
    "    print(f\"Shape: {df_train.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading training data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate and Save External Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sensor_group_plot(df, features, filename_base, output_dir, title_suffix=\"\", sample_frac=100, max_points_marker=5000):\n",
    "    \"\"\"Generates a plot for a group of sensors and saves it as an HTML file.\"\"\"\n",
    "    if df is None or not features:\n",
    "        print(f\"Skipping plot for group {title_suffix}: Data not loaded or no features.\")\n",
    "        return None\n",
    "        \n",
    "    plot_cols = ['time', 'attack'] + [col for col in features if col in df.columns]\n",
    "    if len(plot_cols) <= 2:\n",
    "        print(f\"Skipping plot for group {title_suffix}: Could not find specified features in DataFrame.\")\n",
    "        return None\n",
    "        \n",
    "    # --- Even More Aggressive Sampling --- \n",
    "    rows_before_sampling = df.height\n",
    "    # Adjust threshold and fraction for desired output size/detail trade-off\n",
    "    if rows_before_sampling > 10000: # Start sampling even earlier\n",
    "         print(f\"Sampling data (1/{sample_frac}) for plotting group {title_suffix} ({rows_before_sampling} rows).\")\n",
    "         slice_len = (rows_before_sampling // sample_frac) * sample_frac\n",
    "         df_sample = df.select(plot_cols).slice(0, slice_len).filter(pl.int_range(0, pl.len()).mod(sample_frac) == 0)\n",
    "         plot_title = f'Sensor Readings (Group {title_suffix}) - Sampled 1/{sample_frac}'\n",
    "    else:\n",
    "         df_sample = df.select(plot_cols)\n",
    "         plot_title = f'Sensor Readings (Group {title_suffix})'\n",
    "    # --- End Sampling Logic ---\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    try:\n",
    "        # Add Scattergl traces for sensors\n",
    "        df_sample_pd = df_sample.to_pandas() # Convert once for plotting\n",
    "        for sensor in features:\n",
    "            if sensor in df_sample_pd.columns:\n",
    "                fig.add_trace(\n",
    "                    go.Scattergl(x=df_sample_pd['time'], y=df_sample_pd[sensor], mode='lines', name=sensor)\n",
    "                )\n",
    "        \n",
    "        # Add attack markers using Scattergl\n",
    "        attack_points = df_sample.filter(pl.col('attack') == 1)\n",
    "        if attack_points.height > 0 and attack_points.height < max_points_marker:\n",
    "             attack_points_pd = attack_points.to_pandas()\n",
    "             y_marker_ref_col = next((f for f in features if f in attack_points_pd.columns), None)\n",
    "             if y_marker_ref_col:\n",
    "                 fig.add_trace(go.Scattergl(x=attack_points_pd['time'], \n",
    "                                          y=attack_points_pd[y_marker_ref_col], \n",
    "                                          mode='markers', name='Attack', \n",
    "                                          marker=dict(color='red', size=6, symbol='x', opacity=0.7)))\n",
    "        elif attack_points.height >= max_points_marker:\n",
    "             print(f\"Too many attack points ({attack_points.height}) for group {title_suffix}, skipping markers.\")\n",
    "\n",
    "        fig.update_layout(title=plot_title, xaxis_title=\"Time\", yaxis_title=\"Value\", height=400)\n",
    "        \n",
    "        # Save figure to HTML\n",
    "        filepath = os.path.join(output_dir, f\"{filename_base}.html\")\n",
    "        fig.write_html(filepath, include_plotlyjs='cdn') # Use CDN for smaller file size\n",
    "        print(f\"Saved plot to: {filepath}\")\n",
    "        return filepath # Return path for linking\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during plotting/saving group {title_suffix}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data not loaded, cannot generate plots.\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical sensor columns for plotting\n",
    "if df_train is not None:\n",
    "    exclude_cols = ['time', 'attack', 'attack_P1', 'attack_P2', 'attack_P3']\n",
    "    sensor_cols = [\n",
    "        col for col, dtype in df_train.schema.items() \n",
    "        if dtype in pl.NUMERIC_DTYPES and col not in exclude_cols\n",
    "    ]\n",
    "    print(f\"Found {len(sensor_cols)} numerical sensor columns to plot.\")\n",
    "\n",
    "    # Plot in groups and save externally\n",
    "    group_size = 8\n",
    "    num_groups = math.ceil(len(sensor_cols) / group_size)\n",
    "    plot_links = []\n",
    "\n",
    "    for i in range(num_groups):\n",
    "        start_idx = i * group_size\n",
    "        end_idx = start_idx + group_size\n",
    "        feature_group = sensor_cols[start_idx:end_idx]\n",
    "        filename = f\"sensor_group_{i+1}\"\n",
    "        group_title = f\"{i+1}/{num_groups}\"\n",
    "        \n",
    "        # Use the saving function with more aggressive sampling (e.g., sample_frac=100)\n",
    "        saved_path = save_sensor_group_plot(df_train, feature_group, filename, output_plot_dir, \n",
    "                                            title_suffix=group_title, sample_frac=100)\n",
    "        if saved_path:\n",
    "            # Create a relative path for the link\n",
    "            relative_path = os.path.join(output_plot_dir, f\"{filename}.html\") \n",
    "            plot_links.append(f'<li><a href=\"{relative_path}\" target=\"_blank\">Plot Group {group_title}</a></li>')\n",
    "            \n",
    "    # Display links to the saved plots\n",
    "    if plot_links:\n",
    "        display(HTML(\"<h3>Saved Plot Links:</h3><ul>\" + \"\".join(plot_links) + \"</ul>\"))\n",
    "    else:\n",
    "        print(\"No plots were generated or saved.\")\n",
    "else:\n",
    "    print(\"Data not loaded, cannot generate plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Further Exploration Ideas\n",
    "\n",
    "*   **Correlation Analysis:** Examine correlations between different sensors.\n",
    "*   **Distribution Plots:** Use histograms or density plots for individual features.\n",
    "*   **Time-based Aggregations:** Analyze sensor behavior aggregated over minutes, hours, etc.\n",
    "*   **Load Test Data:** Perform similar initial analysis on the test datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
